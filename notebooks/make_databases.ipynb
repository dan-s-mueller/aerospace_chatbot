{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Import local packages\n",
    "sys.path.append('../src/aerospace_chatbot')\n",
    "import queries\n",
    "import admin\n",
    "import data_processing\n",
    "\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secrets, Models, Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets={}\n",
    "secrets['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "secrets['VOYAGE_API_KEY'] = os.getenv('VOYAGE_API_KEY')\n",
    "secrets['PINECONE_API_KEY'] = os.getenv('PINECONE_API_KEY')\n",
    "secrets['HUGGINGFACEHUB_API_TOKEN'] = os.getenv('HUGGINGFACEHUB_API_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_params=[['ChromaDB','OpenAI','text-embedding-3-large',None],\n",
    "              ['Pinecone','Voyage','voyage-large-2',None],\n",
    "              ['ChromaDB','Hugging Face','Dedicated Endpoint','url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x32cc49a10>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x32d0767d0>, model='text-embedding-3-large', dimensions=None, deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True),\n",
       " VoyageAIEmbeddings(model='voyage-large-2', batch_size=7, show_progress_bar=False, truncation=False, voyage_api_key=SecretStr('**********'), _client=<voyageai.client.Client object at 0x309c3eb90>, _aclient=<voyageai.client_async.AsyncClient object at 0x32ca28d90>),\n",
       " HuggingFaceInferenceAPIEmbeddings(api_key=SecretStr('**********'), model_name='Dedicated Endpoint', api_url='url')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb={}\n",
    "query_model=[]\n",
    "\n",
    "for database in query_params:\n",
    "    sb['index_type']=database[0]\n",
    "    # 'RAGatouille'\n",
    "    # 'ChromaDB'\n",
    "    # 'Pinecone'\n",
    "\n",
    "    sb['query_model']=database[1]\n",
    "    # 'OpenAI'\n",
    "    # 'Voyage'\n",
    "    # 'Hugging Face'\n",
    "\n",
    "    sb['embedding_name']=database[2]\n",
    "    # 'text-embedding-3-large'\n",
    "    # 'voyage-large-2'\n",
    "    # 'Dedicated Endpoint'\n",
    "    # 'colbert-ir/colbertv2.0'\n",
    "\n",
    "    sb['embedding_hf_endpoint']=database[3]\n",
    "\n",
    "    query_model.append(admin.get_query_model(sb, secrets))\n",
    "\n",
    "query_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list=[['OpenAI','gpt-4o',{'temperature':0.5,'output_level':1000},None],\n",
    "            ['Hugging Face','meta-llama/Meta-Llama-3-8B-Instruct',{'temperature':0.5,'output_level':1000},'https://api-inference.huggingface.co/v1'],\n",
    "            ['Hugging Face','mistralai/Mistral-7B-Instruct-v0.2',{'temperature':0.5,'output_level':1000},'https://api-inference.huggingface.co/v1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatOpenAI(tags=['gpt-4o'], client=<openai.resources.chat.completions.Completions object at 0x32d095690>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x32ca292d0>, model_name='gpt-4o', temperature=0.5, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=1000),\n",
       " ChatOpenAI(tags=['meta-llama/Meta-Llama-3-8B-Instruct'], client=<openai.resources.chat.completions.Completions object at 0x32d0ac910>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x32d0b8390>, model_name='meta-llama/Meta-Llama-3-8B-Instruct', temperature=0.5, openai_api_key=SecretStr('**********'), openai_api_base='https://api-inference.huggingface.co/v1', openai_proxy='', max_tokens=1000),\n",
       " ChatOpenAI(tags=['mistralai/Mistral-7B-Instruct-v0.2'], client=<openai.resources.chat.completions.Completions object at 0x32d0bbcd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x32d0c3710>, model_name='mistralai/Mistral-7B-Instruct-v0.2', temperature=0.5, openai_api_key=SecretStr('**********'), openai_api_base='https://api-inference.huggingface.co/v1', openai_proxy='', max_tokens=1000)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_query=[]\n",
    "\n",
    "for query in query_list:\n",
    "    sb['llm_source']=query[0]\n",
    "    # 'OpenAI'\n",
    "    # 'Hugging Face'\n",
    "\n",
    "    sb['llm_model']=query[1]\n",
    "    # 'gpt-4o'\n",
    "    # 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "    # 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "\n",
    "    sb['model_options']=query[2]\n",
    "\n",
    "    sb['hf_endpoint']=query[3]\n",
    "\n",
    "    llm_query.append(admin.set_llm(sb,secrets))\n",
    "\n",
    "llm_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='../data/AMS'\n",
    "docs= glob.glob(os.path.join(data_folder,'*.pdf'))   # Only get the PDFs in the directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_params=[[2,'None',0],\n",
    "              [None,'character-recursive',400]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All query models, standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_type='Standard'\n",
    "summary_llm=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker=data_processing.chunk_docs(docs,\n",
    "                rag_type=rag_type,\n",
    "                n_merge_pages=chunk_params[0][0],\n",
    "                chunk_method=chunk_params[0][1],\n",
    "                chunk_size=chunk_params[0][2],\n",
    "                llm=summary_llm,\n",
    "                show_progress=False)\n",
    "\n",
    "print(f\"Created {len(chunker['chunks'])} chunks from {len(chunker['pages'])} pages.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ChromaDB', 'OpenAI', 'text-embedding-3-large', None]\n"
     ]
    }
   ],
   "source": [
    "i_run=0\n",
    "\n",
    "print(f\"Creating and uploading database with these params: {query_params[i_run]}\")\n",
    "\n",
    "index_appendix=str(chunk_params[0][0])+'merge'+'-'+chunk_params[0][1]+'-'+str(chunk_params[0][2])\n",
    "index_name = (query_params[i_run][2].replace('/', '-').replace(' ', '-') + '-' + index_appendix).lower()\n",
    "\n",
    "# Set index names for special databases\n",
    "if rag_type == 'Parent-Child':\n",
    "    index_name = index_name + '-parent-child'\n",
    "if rag_type == 'Summary':\n",
    "    index_name = index_name + summary_llm.model_name.replace('/', '-') + '-summary' \n",
    "\n",
    "vectorstore = data_processing.initialize_database(query_params[i_run][0], \n",
    "                                    index_name, \n",
    "                                    query_model[i_run],\n",
    "                                    rag_type=rag_type,\n",
    "                                    clear=True, \n",
    "                                    local_db_path=os.getenv('LOCAL_DB_PATH'),\n",
    "                                    init_ragatouille=True,\n",
    "                                    show_progress=False)\n",
    "vectorstore, _ = data_processing.upsert_docs(query_params[i_run][0], \n",
    "                                index_name,\n",
    "                                vectorstore,\n",
    "                                chunker,\n",
    "                                batch_size=400,\n",
    "                                show_progress=False,\n",
    "                                local_db_path=os.getenv('LOCAL_DB_PATH'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

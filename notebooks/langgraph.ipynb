{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test partitioning update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aerospace_chatbot.processing import DocumentProcessor\n",
    "from aerospace_chatbot.services import EmbeddingService, LLMService, DatabaseService, prompts\n",
    "from aerospace_chatbot.processing import QAModel\n",
    "# from langchain_core.documents import Document\n",
    "\n",
    "test_index={}\n",
    "# test_index['db_type']='ChromaDB'\n",
    "test_index['db_type']='Pinecone'\n",
    "test_index['embedding_service']='OpenAI'\n",
    "test_index['embedding_model']='text-embedding-3-large'\n",
    "test_index['llm_service']='OpenAI'\n",
    "test_index['llm_model']='gpt-4o'\n",
    "\n",
    "# setup_fixture={}\n",
    "# setup_fixture['chunk_method']='character_recursive'\n",
    "chunk_size=400\n",
    "chunk_overlap=0\n",
    "batch_size=50\n",
    "\n",
    "index_name = 'text-embedding-3-large-test'\n",
    "rag_type = 'Standard'\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "# Set LOCAL_DB_PATH environment variable\n",
    "# os.environ['LOCAL_DB_PATH'] = os.path.abspath('.')\n",
    "\n",
    "# Initialize logger\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "test_prompt='How does a thermal knife function in a cable based hold down release mechanism?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize services\n",
    "embedding_service = EmbeddingService(\n",
    "    model_service=test_index['embedding_service'],\n",
    "    model=test_index['embedding_model']\n",
    ")\n",
    "\n",
    "llm_service = LLMService(\n",
    "    model_service=test_index['llm_service'],\n",
    "    model=test_index['llm_model'],\n",
    ")\n",
    "\n",
    "doc_processor = DocumentProcessor(\n",
    "    embedding_service=embedding_service,\n",
    "    rag_type=rag_type,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    ")\n",
    "\n",
    "# Initialize database service\n",
    "db_service = DatabaseService(\n",
    "    db_type=test_index['db_type'],\n",
    "    index_name=index_name,\n",
    "    rag_type=rag_type,\n",
    "    embedding_service=embedding_service,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aerospace_chatbot.processing.documents:Number of PDFs found: 2\n",
      "INFO:aerospace_chatbot.processing.documents:PDFs found: ['gs://processing-pdfs/1999_christiansen_reocr.pdf', 'gs://processing-pdfs/1999_cremers_reocr.pdf']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gs://processing-pdfs/1999_christiansen_reocr.pdf',\n",
       " 'gs://processing-pdfs/1999_cremers_reocr.pdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = 'processing-pdfs'\n",
    "docs = DocumentProcessor.list_bucket_pdfs(bucket_name)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioned_docs = doc_processor.load_and_partition_documents(docs,partition_by_api=False, upload_bucket=bucket_name)\n",
    "# partitioned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_obj, output_paths = doc_processor.chunk_documents(partitioned_docs)\n",
    "# chunk_obj.chunk_convert(destination_type=Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aerospace_chatbot.services.database:Validating index text-embedding-3-large-test and RAG type Standard\n",
      "INFO:pinecone_plugin_interface.logging:Discovering subpackages in _NamespacePath(['/Users/danmueller/Documents/GitHub/aerospace_chatbot/.venv/lib/python3.11/site-packages/pinecone_plugins'])\n",
      "INFO:pinecone_plugin_interface.logging:Looking for plugins in pinecone_plugins.inference\n",
      "INFO:pinecone_plugin_interface.logging:Installing plugin inference into Pinecone\n",
      "INFO:aerospace_chatbot.services.database:Pinecone index text-embedding-3-large-test found, not creating. Will be initialized with existing index.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db_service.initialize_database(clear=False)\n",
    "except ValueError as e:\n",
    "    print(f\"Database initialization failed: {str(e)}\")\n",
    "    print(e)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_service.index_data(chunk_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danmueller/Documents/GitHub/aerospace_chatbot/src/aerospace_chatbot/processing/queries.py:47: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  self.memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "qa_model = QAModel(\n",
    "    db_service=db_service,\n",
    "    llm_service=llm_service,\n",
    "    k=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa_model.query(test_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(qa_model.result[-1]['references'])\n",
    "# print(qa_model.sources[-1])\n",
    "# print(qa_model.scores[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(qa_model.ai_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run above section first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, RemoveMessage\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "\n",
    "from typing_extensions import List\n",
    "from typing import Literal\n",
    "\n",
    "from aerospace_chatbot.services.prompts import CHATBOT_SYSTEM_PROMPT, QA_PROMPT, SUMMARIZE_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db_service.retriever\n",
    "llm = llm_service.get_llm()\n",
    "memory = MemorySaver()\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "class LLMResponse(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the response with in-line citations.\")\n",
    "    # citations: List[str] = Field(description=\"List of source citations referenced in the content.\")\n",
    "\n",
    "    # Validator to ensure citations follow the <source id=\"#\"> format\n",
    "    @field_validator('content')\n",
    "    def validate_citations(cls, v):\n",
    "        # Regex pattern to match <source id=\"1\">, <source id=\"2\">, etc.\n",
    "        pattern = r'<source id=\"(\\d+)\">'\n",
    "        matches = re.findall(pattern, v)\n",
    "        \n",
    "        # Raise error if no citations are found or formatting is incorrect\n",
    "        if not matches:\n",
    "            raise ValueError('No valid source tags found. Expected format: <source id=\"1\">')\n",
    "\n",
    "        return v\n",
    "\n",
    "    # # Extract source IDs and populate the citations field\n",
    "    # @field_validator('citations', mode='before')\n",
    "    # def extract_citations(cls, v, values):\n",
    "    #     # Use the content field to extract citations if it's populated\n",
    "    #     content = values.get('content', '')\n",
    "    #     pattern = r'<source id=\"(\\d+)\">'\n",
    "    #     extracted = re.findall(pattern, content)\n",
    "        \n",
    "    #     if not extracted:\n",
    "    #         raise ValueError(\"No citations found in the content. Please ensure sources are cited correctly.\")\n",
    "        \n",
    "    #     # Return the list of extracted source IDs\n",
    "    #     return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResponse(content='\\nThe actuator was tested under high pressure <source id=\"1\">. \\nMaterial properties were measured over 50 cycles <source id=\"2\">.\\nThermal resistance improved by 30% <source id=\"3\">.\\n')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "valid_response = LLMResponse(content=\"\"\"\n",
    "The actuator was tested under high pressure <source id=\"1\">. \n",
    "Material properties were measured over 50 cycles <source id=\"2\">.\n",
    "Thermal resistance improved by 30% <source id=\"3\">.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(valid_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "invalid_response = LLMResponse(content=\"\"\"\n",
    "The actuator was tested under high pressure [1]. \n",
    "Material properties were measured under load <source id=\"x\">.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(invalid_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Define the output parser with the expected Pydantic model\n",
    "output_parser = PydanticOutputParser(pydantic_object=LLMResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Docs content: Source ID: dfca91b6-808a-485c-8f96-9a4ba5a0b56e\n",
      "3. the release/cutting device, consisting of two Thermal Knives for redundancy. The Knives are mounted onto the holddown bracket such that they are able to cut the Dyneema wire bundle\n",
      "\n",
      "Furthermore, the straight aramid cable with endfittings has been replaced by a Reel cable element, for which a patent has been granted. The Reel allows cutting to be almost independent from the application.\n",
      "\n",
      "Source ID: bea2f2a9-2d36-4722-a3e1-b0303d4fad40\n",
      "3.3 Thermal Knife\n",
      "\n",
      "When operated, the Thermal Knife heater plate is pushed through the wire bundle by a compression spring.\n",
      "\n",
      "Source ID: 67113dc6-682d-4ec5-8b9f-21dd25cd923a\n",
      "Both the prime and redundant Thermal Knives operate along the same centre line; as a consequence the heater plates will make contact at their cutting edges after cutting the wire bundle. To assure head-on contact, each Thermal Knife is attached to the holddown bracket under an angle of approximately 8°.\n",
      "\n",
      "Source ID: 6a808f51-f8e5-4d3b-a8e6-18f38e05ab06\n",
      "2. WORKING PRINCIPLE\n",
      "\n",
      "The cable element, named the Reel, consists of 2 abutting parts that are clamped together by a pretensioned Dyneema wire bundle; the clamp load delivers the required holddown load.\n",
      "\n",
      "The lower Reel part is attached to the holddown bracket, which supports the Thermal Knives; the upper Reel part provides the mounting I/F for the deployable\n",
      "\n",
      "Figure 1. MHRM Engineering Model\n",
      "\n",
      "Source ID: 26179cb3-c21e-45ed-8c72-b3dca21196a7\n",
      "application. Up until the moment of release, both Reel parts, due to the presence of the pretensioned wire bundle, constitute a single unit, capable of holding down the application during launch and ascent to the intended orbit. During release, the Thermal Knife cuts the wire bundle, thus releasing the upper Reel part from the lower part and enabling the upper part to deploy along with the\n",
      "\n",
      "Source ID: 2fb4ff32-08fd-4a8d-935f-65f58e1ac404\n",
      "The Thermal Knife support flanges provide M5 wire inserts (4 in total), suitable for installation of optional kick-off spring plungers. As a rule, some customers require the possibility to apply kick-off springs near separable surfaces. During Engineering Model testing kick-off spring plungers were not part of the MHRM.\n",
      "\n",
      "Source ID: a3c55cba-dea7-4800-957d-e77471a29db8\n",
      "The results were such that for the 50 Volts version of the Thermal Knife, a voltage range from 48 to 52 is recommended. Release time will then range from 5 (hot case) to 20 seconds (cold case).\n",
      "\n",
      "Source ID: 7f42ac88-49e4-44ad-bd7c-0d6c241a7727\n",
      "The holddown bracket, which is in general attached to the satellite, supports the Thermal Knives and passes the mechanical loads exerted by the application on the Reel, to the S/C structure during launch. Its shape is straightforward: two flanges for Thermal Knife support perpendicular to a base plate onto which (in-between the flanges) the Reel is mounted. The base plate’s footprint is 50 by 60\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(test_prompt)\n",
    "\n",
    "# Add context to the prompt\n",
    "# TODO update this to use the doc.id\n",
    "docs_content=\"\"\n",
    "for i, doc in enumerate(retrieved_docs[0]):\n",
    "    docs_content += f\"Source ID: {i}\\n{doc.page_content}\\n\\n\"\n",
    "logger.info(f\"Docs content: {docs_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='dfca91b6-808a-485c-8f96-9a4ba5a0b56e', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': 'dfca91b6-808a-485c-8f96-9a4ba5a0b56e', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJzlU8Fu2zgQ/RVCZ0cWZckycy4WWGyxWLS5BYEwIkcWsRQpkFRco+i/d0grTVCkx71sj3wzj/M4fO/xa4EGZ7Sx16q4ZwUXDQy8hlo1R962bS0PbYVKNBUXR1B1sWPFjBEURKD+r4V0zittIWLIZwNXt8Z+Qn2eIiF1XVXE2eCLVnEilHcZXZy2MfEeH0XVlmLH+IGfSvG0Yz+ApjmUbQJ4I0TZvovcSAQV4Roizukl/+gvaD4vILH4RoUkuA9u9XROOj1KEt4bJyE6n6HFu+ikM4l9DumlHmcXsR+1wX6BrJwq9/s9tUoMQdvz3aLGkCes3vyqvudCiF7SdehD79FJXxJ+E4YRZdTO9tJACD1RB7qnKgUXXU0NebrSJJiEXtOIcq+cXPOvvQ4qtlYLM95+8t2RW1e8LrkLlsVoWgHN329lA/a8wjn/52OBdPNTRkPsZ6f0qDE7pa7q5o7Xd/XxgTf3h+q+qRJ7IWZv13nAtFSeEf/qr0GpoZNNp6Qij9XHgzyIFshax2ochlHllUT8kqxTHEoWJ2SeLAoB93KNkR7KFD5riTsmnQ06ZMiNLF4ce5jQz2DYX1Y/Y2Cj80RWq1Vg5bVM5ZcSaWKzW21ExZyNLg+anFHKXSwbPMh/MbKwyokqEFP5mkkwGGTUT2Iy58PVIs7ALvRBbKBRBtMaXvb7kQT+mRxJ7/o5azDC2EHdtlzhiYuxaRs4jdgMlYCma07/WdZ4d9qCJLYgbUDb8fKQgFPVldV7wI3yP0vaSRzb5rdO2h+rjyk7zlOukq1D9JBcRZ6HWSsms+8vOk4MrRp1TmJgEwQ2IFqK2WLIAIoNFBP2CdFslM3yuxzGy6QpUMDohwl7ZZ89pCTeEprJYIy7BPYSeQrcQNkzswuRaatwIRXpitG7OQt+s97ybQD/Bu8JfcaH9NRvT98BKBg8LQ==', 'page_number': 1.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='3. the release/cutting device, consisting of two Thermal Knives for redundancy. The Knives are mounted onto the holddown bracket such that they are able to cut the Dyneema wire bundle\\n\\nFurthermore, the straight aramid cable with endfittings has been replaced by a Reel cable element, for which a patent has been granted. The Reel allows cutting to be almost independent from the application.'),\n",
       " Document(id='bea2f2a9-2d36-4722-a3e1-b0303d4fad40', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': 'bea2f2a9-2d36-4722-a3e1-b0303d4fad40', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJzdVMGO2yAU/BXkc+KATeI4v1CpqtRIPUQrC8OzjYQNAtzdaLX/3gdJtdtq99BDD+0JMW+GNzzGvjwXYGCGJXZaFSdS1MB53XM+7Jt+r3ql2pZXomFNBW3PpCg2pJghCiWiQP5zIa31Si8iQsh7I652jd0EepwiIlVFKWru8KNWcUKUNRl1Vi8x6S4XdqQl2xBGKSuPDxvyClRtyRLAKS3pu0CWIFKEa4gwp3t80U9gvjohoXjBQrLbBbt63CeXHiTa7oyVIlqfIedttNKapB5DuqeH2UboBm2gcyL7xsppt0OqhBD0Mm6dGkLusHrzUX3H2rbtJB4HPnQerPQl4jdjEEFGbZdOGhFCh9Iez6HlkdXVHgm5u9JoGI1eU4typ6xc85u9Niru1EXM6YbFBy3vrHh1mSWcMxpHgP1397IRy7iKMb/mpQA8+SGjIXazVXrQkHNS0YpvWbWtDmfGTzU9cZrUDpXdss49pKHW6YYRnmJOVlmT8wR+FoZ8WvQAif/TyFlHk1/q9zwqaKQYeLNv9ocBqGjrhks40qPi/VDv27+Xx6a9xa+uyybn8Q6wit/i19SHsnoPuEn+szy27Hjg/3oeM+L/4G/3NsDfJliIdeAxW2pD4gS/5plMgBVPnMGF6EDcGiZQSPR2HacseMTBkX5dlMHlSgSRdnY+jcwuJDiPkyvffhefhcd2+juck4mXhx+KLMln', 'page_number': 3.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='3.3 Thermal Knife\\n\\nWhen operated, the Thermal Knife heater plate is pushed through the wire bundle by a compression spring.'),\n",
       " Document(id='67113dc6-682d-4ec5-8b9f-21dd25cd923a', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': '67113dc6-682d-4ec5-8b9f-21dd25cd923a', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJx1UsFu2zAM/RXC58axHTuOs9uuA4YByy0rDFqiY6Gy5Eny0qDov49S022HFfDFj+/xPZE8v2SkaSYTeiWzI2SHZqzGsjgUTSNbKg94wEKWTSWwKWpZV9kDZDMFlBiQ+S+ZsNZJZTCQT/8ab3YN/UTqMgVGqqooWHOHr0qGidGyTehilQlRdz6XhyJvHqAs90VePz7AH2BXt3kZgfbQ5fv/AW8SRjJ/84Hm+I5v6pn09wUFZa9ciHF7b1fH/zGlI8Gxe20FBusStDgbrLA6qi8+vtPRbAP1o9LUL5hyc+W43TJVkPfKXDaLHH1yWJ3+qL4tu67rBbcj53tHVric8bdgFEgEZU0vNHrfs3TgPkXe1e2+ZkJyl4oDc9BbtMi30oo17eyvUXanGpzjC7MPLO+scFsSC5dFKx4B+2/vZY3msuIlbfOcEXd+TKgP/WylGhWlO6mKqt6U1aban8r6uCuOdRHVCyt7s84DxaHuEuL+XteO6no31PXYtEMjBym7rq6wLduKuqEUmEYS6DkeTvbZhgnCRLA4NROgkeBIrkaiCXCayM2o4YtRv8iDXcjxCQJqay5J5HkQINjaEWhl6BOgBwRhjaefKxlBiTYRyxwsOh4wXJXWMOMTRV5AEQBDpCkHYg2B5wwkeTaAY1S9Y7HRlVcEA6fTlMPJsptfXeovN9a893sAQjH9m34kUNwvcHUiCcG+xbJaSns1MDgUTxSAG7MhGv4umsCOwLtz9lnNHFzf4PBjLYqhyOMS3rf7FR0PhedzihN9ffwN5HNHDg==', 'page_number': 3.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='Both the prime and redundant Thermal Knives operate along the same centre line; as a consequence the heater plates will make contact at their cutting edges after cutting the wire bundle. To assure head-on contact, each Thermal Knife is attached to the holddown bracket under an angle of approximately 8°.'),\n",
       " Document(id='6a808f51-f8e5-4d3b-a8e6-18f38e05ab06', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': '6a808f51-f8e5-4d3b-a8e6-18f38e05ab06', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJzdV01v3DYQ/SuEzrZWIkVKdI9p0hqpXcM10INhCPwY7gqVRFWi7CyC/veOqHXjphsUOfjgPepxHmc4evNE3X9OoIUO+lA3NrkgSeVAWcuAs6zUUjijhKOMg8udA2Gy5IwkHQRlVVAY/zkx3o+26VWAKT63au/nUO+g2e4CIpRmGXIO8FNjww7RvIzo4Js+LLz7e0aLlJ3hQpmn1cMZ+QJItgKCV2l+FIgURJJpPwXolnPcNJ+g/W1QBpK/cGEpt578POLzUuUIBsuuW29U8GOEhtEHb3y7sLfTcs4ROh+gdk0L9aBi3bhysdlgqIFpavrt+WDdFDPMY/ut9U0upawNbgfjVI/gzZgivhYGAUxofF+bVk1TjVSN+2RpxQXjGBCz2wYLxkL3S4p0Y72Z4zv7kig5hPaqW06YfCPlISrshxilhqFtsAWYf3NYblW/ndU2vs37BHDnh4hOoe68bVwDUSc0o8V5Ts+puMuLC5ZdFFEaAzLrfu40LE3NlxMG+BQiIyW//3r78fL6J3Jze3n97vLml/cL5bmWuya08WV9LcmyVFYzxyTlLmcZlSUVKIIyozp3hstXk2Re0bRAfVWsSOkiuGdA8jwtF6DKqlQcA1bKqUlS8EK8dUlGZPwOw3up4bsdEKN0C+Qg0TOynM6SgAu3AO0ZMb6fmilMxDtCidJzCNgLgjkRCzsVCGYn2NluWHh+C8gdid4TRYYRW4903+PSj/seoFPkCRtN9NzbFn6IeSKXtF5ZYqFtHrGdER/hzxljLdn51lr/1MeY9OWMXatxxNY+wt1yoCOzJhl1mQJrqZVOGiuyggMzRppKFbx4vVmTWZai3eVFKVK5TNIzIHl2GD7OeJodRVbSiU2bpFLmb33aXg7PSyFedhh3TIBCgIXCcAsUZCEKXbCcUW0zqbUTwrye2ZdytXKRH9S1AjRDuWWrt5dpeQQ4UE5MfhXL5Js3+6+9u/VP6LWLUUdDJs1EVAjK7KIVRxf9xzz1qMwfgA7/tGvMjkzzMPjVw4HgXmOnWvKxRy+dVlvG9X/tjb15bCyshM7PffwOXG4+EOfHCFoYWr9fPiff5dFCl1bbgjMNyjnlSsElEwWvmAEmS/2KHs3jfVsKnvLVow+ALNM8zgwrxOrR/0Ui6cSGpKwElac0JB+a7YzXjTwlVz/fXpH3/bbBW8i4KPfK423jpVDX2HdqWCo7JlQLzvHK8FwzXRqttLW2EJUwpXEOwVf08iqlqDlRrj+Kh2fB0NFX45bHntf4E5MofkSrt/4fSf/nGvHwN58pSok=', 'page_number': 1.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='2. WORKING PRINCIPLE\\n\\nThe cable element, named the Reel, consists of 2 abutting parts that are clamped together by a pretensioned Dyneema wire bundle; the clamp load delivers the required holddown load.\\n\\nThe lower Reel part is attached to the holddown bracket, which supports the Thermal Knives; the upper Reel part provides the mounting I/F for the deployable\\n\\nFigure 1. MHRM Engineering Model'),\n",
       " Document(id='26179cb3-c21e-45ed-8c72-b3dca21196a7', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': '26179cb3-c21e-45ed-8c72-b3dca21196a7', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJx1U01v2zAM/SuCz6kTO05c9zjsMgwYhq07FYVBS3QsVJY8iVoaFP3vo9R0bbf1qMeP9/hI3TwUaHBGS71WxZUooGnb/Q66rRxGta1bud93soMOQLUg232xEsWMBAoIOP+hkM55pS0Qhvw2cHKR+gn1YSJG6nqz4ZozfNSKJkarNqOL05ZS3c3NZdeW3Uo0XVNub1fi+d1ttmWT3tWubsv2P8BTBSNFOAXCOU3xVd+j+b6AxOKRA0lsH1z0/E4aPUoW3RsngZzP0OIdOelMqj6ENKXH2RH2ozbYL5BVc+RqveZUiSFoe7hY1BgyQ/Tmvfi66rqul9wOfeg9OulLxp+EIaEk7WwvDYTQc+nAfTZl12z2e07I7EqzYBZ6ShTlWjkZ88ZeiIpzqoU5TVi8Q3nOotOSs2BZjGYLmH99DhuwhwiHvMubArnzbUYD9bNTetSYr6Te1M1FVV/U++uqudpurppNql64srdxHjCZWmXEv9zWfnfZqHG3rWErVTN2TQfVUO92426UQ7WrsiWE9/SXuFL8WES0pI2gCcXs0vTCjcLz7ULAlRgcTeIbohFMSGElVERBLqcvHgNaiang/Ca0gfuiEke2VgzRKsNdpLOBNEVCASLZapBpNXEEFhhMbjE5w+d+EModbe73SijT+hQzEK2cBFglIMgk9qyFrx2tYl7nB02l+PiU/2eOlHM9oZ/BiM9WjyhkpJDhN0ppiuFclepTPC4L+hcPxOjdnAPGHTmQsSSIb2Qwb4tyjBUqXIw7CTCOw0fNlv49XwL5G4swOXlXig8oIQbMaZn5xcHwj4WRKNFqjpjZBWIzmDDZYV+pfbP2T/YicDdx3lcq5w28SknWAP0R/sy4gGUxzGSdSMPwjB5/RnZQrcRx0rybGe5Y48SOZDPYyFOZTvj5b3wB75niF16ne3y8/Q3Djb1x', 'page_number': 1.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='application. Up until the moment of release, both Reel parts, due to the presence of the pretensioned wire bundle, constitute a single unit, capable of holding down the application during launch and ascent to the intended orbit. During release, the Thermal Knife cuts the wire bundle, thus releasing the upper Reel part from the lower part and enabling the upper part to deploy along with the'),\n",
       " Document(id='2fb4ff32-08fd-4a8d-935f-65f58e1ac404', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': '2fb4ff32-08fd-4a8d-935f-65f58e1ac404', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJx1U+9r2zAQ/VcOf9ogcWzFP+p8G2wwGBlj67dQjCKdE1FZ0iS5bSj733dSUwob/WDQPd3de/dOPjwXqHFGE0clix0UnLWtmFCKvj6inJjAYWAtF3KLnJCmWEExY+SSR075z4Ww1ktleMSQY80vdonjGdXpHAlhrKqo5go/KhnPhNZ9Rp1VJqa6w6G+qctuBU23Lbu7FbzGXdOWLMX90JfD//FLPgFFuISIc5rhh3pC/ctxgcUfukhSx2AXT3FS6FGQ5FFbwaP1GXLeRiusTtWnkGb0ONuI46Q0jo5nzXSz22woVWAIypzWTk4hMyxev3e/qYdhGAW1Qx9Gj1b4kvAXYRhRRGXNKDQPYaTSI/WpypthW7WUkNmlIsEk9JIoyo20Ysn7eiMqrqmGz2nC4h3Ka1a8uJzFndOKLCD+zfVac3Na+Clv8lAgdb7LaIjjbKWaFOY3wirWrGu2Zt1t3ey21a6pUrWjytEs8xGTqduM+LeXNUjs2HBs2xuBvZQMexzqtpOsQtbLusmWRHxKj6a4PSPQ52eu4ZtRE0JYnLM+wpREYgAa/0FJhH0Lj+QQKBPQxwAfGjpCtJHrjyuqUpEfNcJkfUohVOeRwU5gXToRw70S92s7TRCcJz/B6YU4fCjhUwAOftFIreyMIJYQbfIVPP5eEm8kpc7SHo5Kq3ghZkjOXv5tGsAg9xCQTMmKwuIneqJE8nnJrF/MSRnEfN5biRron4opek8fPCIpMDYCNY1ppKRm//XnvkwLed30d+49Df2At8ndP3d/ASsqTW8=', 'page_number': 3.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='The Thermal Knife support flanges provide M5 wire inserts (4 in total), suitable for installation of optional kick-off spring plungers. As a rule, some customers require the possibility to apply kick-off springs near separable surfaces. During Engineering Model testing kick-off spring plungers were not part of the MHRM.'),\n",
       " Document(id='a3c55cba-dea7-4800-957d-e77471a29db8', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': 'a3c55cba-dea7-4800-957d-e77471a29db8', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJx1UsGO2jAQ/ZWRT7sSBMckEPiFSlXVol4Qsow9IZacOLIdWLTaf+84sGoP3ZvnzXszb8ZzfGfosMchSWvYHpg51zvExpRtKURdlXqzUdpslapLtd6Jhi2A9ZiUUUkR/51p74Oxg0oY59ipu5+S7NBeukSIEJyT5gnfrEkdoeV2Rkdvh5R1x+OO82K7gE3ZFPy0gM94W/FC5LisxbYQ/wEeCkJYvMeEfZ7ih31D92tUGtkHJbJZGf0UKM4eA2oyLZ3XKvkwQ2PwyWvvsvoS85QBe59QttahHNXsmjL71YqoGmO0w2U5mjbOHabgvsqvyt1uJzWVwxBlQK9DQfjDGCbUyfpBaqdilCQ9Ux1eNJu1aIgwdzeWDJPRe25RrIzX0/xjfxuxJ3VQfZ6QfdHyyUr3cWapcXSWVkD9V8+0U8NlUpf5L48MqfJpRmOSvTe2tThfieCiWpZiKTaHstqv+b7iWT2SUg5Tf8a81CpPmPAtXwE7dAgB4+RShBsGhDjpDlKnErQ+0AOh5vDb5/yVXJMn8O2MkzT0ysG3wba4AAVXYlEnCGQWoQ2+h6qB5KEWYCPk3+1pQQZNAT/pvFVESLZHuFnncsnhX2kNL51PoIn1mosIDpEqDCbCCx2EeWSKPN/n4r6rEGhtVzzk6T5OfwAiYwuh', 'page_number': 4.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='The results were such that for the 50 Volts version of the Thermal Knife, a voltage range from 48 to 52 is recommended. Release time will then range from 5 (hot case) to 20 seconds (cold case).'),\n",
       " Document(id='7f42ac88-49e4-44ad-bd7c-0d6c241a7727', metadata={'chunk_overlap': 0.0, 'chunk_size': 400.0, 'data_source.record_locator.protocol': 'gs', 'data_source.record_locator.remote_file_path': 'gs://processing-pdfs', 'data_source.url': 'gs://processing-pdfs/1999_cremers_reocr.pdf', 'element_id': '7f42ac88-49e4-44ad-bd7c-0d6c241a7727', 'file_directory': './document_processing', 'filename': '1999_cremers_reocr.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2024-12-26T14:30:40', 'orig_elements': 'eJx1U8Fu2zAM/RXBpw1IHFlxnDjXnYYBw7D2lhWGLDGxMFkSJLppUOzfRznJWmAo4AsfH8nHR/nwWoCFERx2Rhd7Vqh60x51w1XdNBo20PBaCd5uxVrwqu5FsWDFCCi1REn810J5H7VxEiHNsZUXP2E3gDkNSIgQnFPNDT4bjQOh1XZGgzcOc93hUO2qUiyY4Jty+7Rg97ium7LN8bZtSv5/fOUTUKRLQhjzDj/MC9iHIBUUfyiRpXbJT5HirDCCIsmd9UqijzMUokevvM3Vp5R3jDB6hO5oLHRBzpops1+tiKogJeNOy6CPaZ4wRftRflW1bdspagcxdRG8iiXhV2GAoNB41ykrU+qotKc+vNzteLMmwjxdGxJMQi95RLnSXk3zvd4GFTeqk2PesPhg5I2FlzCzZAjWkAU0f3VLW+lOkzzNlzwUQJ2fZjRhN3ptjgbmNyK4qJeVWIrmsar3a76vea4OVNm5aewhm7qekfj2sloNjWj7zWanYKu1gC201abRgoPY6qqeLUF4yY+meByADd5q7c+O9VGq34ALdh6MGphJzDh2AgdRWiYRpRpAM/QMqSrRS7TWICxYmkLwEdOMU8c4Ev+bM8+QmHSaBTIdrtkR1CAd2WGZ9VInBi8Qkbr2lzn/zixGX4Z+AtjFferD6gtLGCeFUwSmp0hnYVZOTg0l+0oS0iADZOnEkvnXOPp4llHvGZ49O2bnSQqB74Ue4b4DCxADOG3UZGXMUyXrZQIWLO1Lkgi5uvPJuGUPeAa4yry1/vxPcxYx+snRdmUe9q7Pr4l+8jbL8BhoBczcDc8mNJyNY5nPfH8/32WMZMgzPOab/Xn6C/5UaDE=', 'page_number': 3.0, 'rag_type': 'Standard', 'type': 'CompositeElement'}, page_content='The holddown bracket, which is in general attached to the satellite, supports the Thermal Knives and passes the mechanical loads exerted by the application on the Reel, to the S/C structure during launch. Its shape is straightforward: two flanges for Thermal Knife support perpendicular to a base plate onto which (in-between the flanges) the Reel is mounted. The base plate’s footprint is 50 by 60')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_with_context = QA_PROMPT.format(\n",
    "#     question=test_prompt, \n",
    "#     context=docs_content\n",
    "# )\n",
    "\n",
    "# Create a prompt template that includes format instructions\n",
    "# prompt_template = PromptTemplate(\n",
    "#     template=\"Answer the user query with in-line citations in the format [Source #].\\n{format_instructions}\\n{query}\",\n",
    "#     input_variables=[\"query\"],\n",
    "#     partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    "# )\n",
    "\n",
    "QA_PROMPT=PromptTemplate(\n",
    "    template=\n",
    "\"\"\"\n",
    "Your name is **Aerospace Chatbot**, a specialized assistant for flight hardware design and analysis in aerospace engineering.\n",
    "\n",
    "Use only the **Sources and Context** from the **Reference Documents** provided to answer the **User Question**. Do not use outside knowledge, and strictly follow these rules:\n",
    "\n",
    "---\n",
    "\n",
    "### **Rules**:\n",
    "1. **Answer only based on the provided Sources and Context.**  \n",
    "   - If the information is not available in the Sources and Context, respond with:  \n",
    "     *\"I don’t know the answer to that based on the information provided. You might consider rephrasing your question or asking about a related topic.\"*\n",
    "\n",
    "2. **Do not make up or infer answers.**\n",
    "\n",
    "3. **Provide responses in English only** and format them using **Markdown** for clarity.\n",
    "\n",
    "4. **Cite Sources in context** using the exact format `<source id=\"#\">`:  \n",
    "   - `#` – Represents the numerical order of the source as provided in the Sources and Context.  \n",
    "   - **The `source` tag must be present for every source referenced in the response.**  \n",
    "   - **Do not add, omit, or modify any part of the citation format.**  \n",
    "   \n",
    "   **Examples (Correct):**  \n",
    "   > The actuator was tested under extreme conditions <source id=\"1\">.  \n",
    "   > A secondary material exhibited increased yield strength <source id=\"2\">.  \n",
    "   > Additional research confirmed thermal properties <source id=\"3\">.  \n",
    "\n",
    "   **Examples (Incorrect – Must Be Rejected):**  \n",
    "   > Testing yielded higher efficiency [1] (Incorrect bracket format)  \n",
    "   > <source id=\"1\" > (Extra space after `id`)  \n",
    "   > <source id=\"a\"> (Non-numeric ID)  \n",
    "   > <source id=\"1,2\"> (Multiple IDs in one tag – invalid)  \n",
    "\n",
    "5. **Every sentence or paragraph that uses a source must cite it with the format `<source id=\"#\">`.**  \n",
    "   - **Do not group multiple sources into a single tag.** Each source must have its own, clearly separated citation.  \n",
    "   - For example:  \n",
    "     > The actuator uses a reinforced composite structure <source id=\"1\">. This design was validated through multiple tests <source id=\"2\">.  \n",
    "\n",
    "6. **Validation Requirement:**  \n",
    "   - If the response contains references without the exact `<source id=\"#\">` format, the response must be flagged or rejected.  \n",
    "   - Every source used must have a corresponding citation in the response. **No source should be referenced without explicit citation.**  \n",
    "\n",
    "7. **Suggest related or alternative questions** if applicable, to help the user find relevant information within the corpus.\n",
    "\n",
    "\n",
    "---\n",
    "**User Question**:\n",
    "{question}\n",
    "---\n",
    "\n",
    "---\n",
    "**Sources and Context from Reference Documents**:\n",
    "{context}\n",
    "---\n",
    "\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Generate and parse the response\n",
    "# def generate_response(question: str, context: str) -> LLMResponse:\n",
    "#     prompt = QA_PROMPT.format(question=question, context=context)\n",
    "#     raw_output = llm(prompt)\n",
    "#     return output_parser.parse(raw_output)\n",
    "\n",
    "prompt = QA_PROMPT.format(question=test_prompt, context=docs_content)\n",
    "raw_output = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A thermal knife in a cable-based hold-down release mechanism functions by cutting through a wire bundle to release the hold-down load. Specifically, the thermal knife consists of a heater plate that is pushed through the wire bundle by a compression spring <source id=\"1\">. Both the primary and redundant thermal knives are mounted on the hold-down bracket and operate along the same center line, ensuring that their heater plates make contact at their cutting edges after cutting the wire bundle <source id=\"2\">. This cutting action releases the upper part of the Reel from the lower part, allowing the upper part to deploy <source id=\"4\">.\n"
     ]
    }
   ],
   "source": [
    "print(raw_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.parse(raw_output)\n",
    "\n",
    "# generate_response(test_prompt, docs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    context: List[Document]\n",
    "    summary: str\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    \"\"\"\n",
    "    Retrieve the documents from the database.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Node: retrieve\")\n",
    "\n",
    "    retrieved_docs = retriever.invoke(state[\"messages\"][-1].content)\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "def generate_w_context(state: State):\n",
    "    \"\"\"\n",
    "    Call the model with the prompt with context.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Node: generate_w_context\")\n",
    "\n",
    "    # Get the summary\n",
    "    # TODO add conversation modes\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    if summary:\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "        messages = [CHATBOT_SYSTEM_PROMPT] + [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "        # logger.info(f\"Messages with system prompt (w/summary): {messages}\")\n",
    "    else:\n",
    "        messages = [CHATBOT_SYSTEM_PROMPT] + state[\"messages\"]\n",
    "        # logger.info(f\"Messages with system prompt (w/o summary): {messages}\")\n",
    "    state[\"messages\"] = messages\n",
    "\n",
    "    # Add context to the prompt\n",
    "    docs_content=\"\"\n",
    "    for i, doc in enumerate(state[\"context\"][0]):\n",
    "        docs_content += f\"Source ID: {i}: {doc.page_content}\\n\\n\"\n",
    "    logger.info(f\"Docs content: {docs_content}\")\n",
    "\n",
    "    prompt_with_context = QA_PROMPT.format(\n",
    "        question=state[\"messages\"][-1].content, \n",
    "        context=docs_content\n",
    "    )\n",
    "\n",
    "    # Replace the last message (user question) with the prompt with context, return LLM response\n",
    "    state[\"messages\"][-1] = prompt_with_context \n",
    "    # logger.info(f\"Messages with prompt with context: {state['messages']}\")\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "def should_continue(state: State) -> Literal[\"summarize_conversation\", END]:\n",
    "    \"\"\"\n",
    "    Define the logic for determining whether to end or summarize the conversation\n",
    "    \"\"\"\n",
    "    logger.info(f\"Node: should_continue\")\n",
    "\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    messages = state[\"messages\"]\n",
    "    if len(messages) > 6:\n",
    "        logger.info(f\"Summarizing conversation\")\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise just end\n",
    "    logger.info(f\"Ending conversation\")\n",
    "    # logger.info(f\"Messages before ending: {messages}\")\n",
    "    return END\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \"\"\"\n",
    "    Summarize the conversation\n",
    "    \"\"\"\n",
    "    logger.info(f\"Node: summarize_conversation\")\n",
    "\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    if summary:\n",
    "        # If a summary already exists, extend it\n",
    "        summary_message = SUMMARIZE_TEXT.format(\n",
    "            summary=summary,\n",
    "            augment=\"Extend the summary by taking into account the new messages above.\"\n",
    "        )\n",
    "    else:\n",
    "        # If no summary exists, create one\n",
    "        summary_text=\"\"\"---\\n**Conversation Summary to Date**:\\n{summary}\\n---\"\"\"\n",
    "        summary_message = SUMMARIZE_TEXT.format(\n",
    "            summary=summary_text,\n",
    "            augment=\"Create a summary of the conversation above.\"\n",
    "        )\n",
    "\n",
    "    messages = state[\"messages\"] + [summary_message]\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # Prune messages. This deletes all but the last two messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the conversation node and the summarize node\n",
    "workflow.add_node(\"retrieve\", retrieve) \n",
    "workflow.add_node(\"generate_w_context\", generate_w_context)\n",
    "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate_w_context\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # Define the start node. We use `generate_w_context`. This means these are the edges taken after the `conversation` node is called.\n",
    "    \"generate_w_context\",\n",
    "    # Next, pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# Add a normal edge from `summarize_conversation` to END. This means that after `summarize_conversation` is called, we end.\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = graph.invoke({\"question\": test_prompt}, config=config)\n",
    "\n",
    "prompt = 'My name is Dan. Please tell me about some interesting mecanism designs.'\n",
    "result = app.invoke({\"messages\": [(\"human\", prompt)]}, config)\n",
    "for message in result['messages']:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'How have these mecahnisms been tested?'\n",
    "# result = app.invoke({\"messages\": [(\"human\", prompt)]}, config)\n",
    "# for message in result['messages']:\n",
    "#     message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'How old are you?'\n",
    "# result = app.invoke({\"messages\": [(\"human\", prompt)]}, config)\n",
    "# for message in result['messages']:\n",
    "#     message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'What are some lessons learned about these mechanisms?'\n",
    "# result = app.invoke({\"messages\": [(\"human\", prompt)]}, config)\n",
    "# for message in result['messages']:\n",
    "#     message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = 'What are some problems that have occurred?'\n",
    "# result = app.invoke({\"messages\": [(\"human\", prompt)]}, config)\n",
    "# for message in result['messages']:\n",
    "#     message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch/ragas\n",
    "Test batch and ragas capability.\n",
    "\n",
    "Uses this article as a model: https://towardsdatascience.com/visualize-your-rag-data-evaluate-your-retrieval-augmented-generation-system-with-ragas-fc2486308557\n",
    "\n",
    "Ragas repository: https://github.com/explodinggradients/ragas/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ragas.testset import TestsetGenerator\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import chromadb\n",
    "from chromadb import PersistentClient\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "\n",
    "# Set environment variables with .env\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "persistent_client = chromadb.PersistentClient(path=os.path.join(os.getenv('LOCAL_DB_PATH'),'chromadb'))   \n",
    "query_model=OpenAIEmbeddings(model='text-embedding-ada-002',openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "# Connect to vectorstore where no chunking was done only full PDF pages\n",
    "vectorstore = Chroma(client=persistent_client,\n",
    "                        collection_name='chromadb-openai-ams-full',\n",
    "                        embedding_function=query_model)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = vectorstore.get(include=[\"metadatas\", \"documents\", \"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcdocs = [Document(page_content=doc, metadata=metadata) \n",
    "          for doc, metadata in zip(all_docs['documents'], all_docs['metadatas'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99472a20fcef47b4b90be13bcdd93c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/204 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b7b9e598a3483790bd20eb8254e874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator_model=\"gpt-3.5-turbo-16k\"\n",
    "critic_model=\"gpt-4\"\n",
    "\n",
    "generator_llm = ChatOpenAI(model=generator_model)\n",
    "critic_llm = ChatOpenAI(model=critic_model)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "n_docs=100\n",
    "testset = generator.generate_with_langchain_docs(lcdocs[:n_docs], test_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestDataset(test_data=[DataRow(question='What are the different material combinations tested for the gliding surfaces in the hinge system?', contexts=['350 Development :  In a preliminary development study , the principle of the hinge was  developed and a functional verification  was run with a modifiable demonstrator model , shown in Figure 6, to prove the concept functional ity. The  hinge for the demonstration model  is designed to have a broad range of adjustable functional parameters  as to accommodate different springs and featur ing an adaptable spring force and stroke  length to vary the  kick-off energy.  The demo nstrator consists of  a fairing dummy, down scaled from a large launch vehicle.  The dummy was constructed with adaptable mass distribution, in order to simulate possible design changes  on the fairing for the new separation system as well as asymmetric mass distribution to assess the  robustness of the system  by test . Only one hinge has been attached to the demonstrator, allowing to  investigate and test occurrence of jamming due to asymmetric actuator force introduction.  \\n\\nFigure 6: Early stage hinge during concept test ing on the demonstrator  model  \\n\\nThe demonstrator  test verified the principle of the system as well as the concept of the hinges. Several test  variations in terms of initiated force direction, energy variation of actuator  and kick -off-spring were  conducted and showed the high robustness for the new jettison system.  By varying a broad range of  parameters, the concept also proved to be scalable to the use for different launcher classes  with low  additional work.  \\n\\nLesson Learned  and Research:   Along with the  successful verification of the hinge’s  principle and initial correlation  to analysis, t hose tests  showed that an improvement of the tribological behavior of the hinge’s gliding surfaces was necessary , i.e.,  the kick -off plunger to the axle and the suspension to the guiding pin. Consequently,  a dedicated trade off  and testing campaign was conducted to find a suitable material combination which ensures a low friction  and avoids abrasion, jamming or cold weldin g. \\n\\nThree different material combinations , including a bearing,  were selected by a tradeoff  and tested   extensive ly for gliding  movement  with high forces  towards each other . The involved materials for the gliding  surfaces are aluminum with Ematal coating and stainless steel. For the counter -acting surface t hree  different materials and corresponding coatings were tested:   • Material 1:  Titanium  with Dicronite coating   • Material 2:  Stainless steel  with fiber reinforced plastic composite bearing   • Material 3:  Stainless s teel with Teflon- filled coating'], ground_truth='Three different material combinations were tested for the gliding surfaces in the hinge system: Material 1: Titanium with Dicronite coating, Material 2: Stainless steel with fiber reinforced plastic composite bearing, Material 3: Stainless steel with Teflon-filled coating.', evolution_type='simple', metadata=[{'page': 360, 'source': 'AMS_2020.pdf'}]), DataRow(question='What is the connection between angular runout and bearing preload loss in temperature gradient tests?', contexts=['411                   Figure 9. Pupil Wheel Bearing Test at 35K viewed through Test Fixture Window \\n\\nBearing Test 1  Objective:  To quantify the temperature gradient ac ross the bearing when preload is lost.  Pupil wheel bearing was torque tested with various temperature gradients across the bearing. Result:   Preload was lost when temperature gradient exceeded 5K . This result agreed with analytical prediction.  Preload is lost because outer race is temporarily too large to maintain contact with the balls.   \\n\\nBearing Test 2:  Objective:  To measure the bearing initial torque at 35K, having periodically rotated the  bearing from 150K down to the operating temperature. The purpose of the test was to see if a mitigating strategy could be implemented during the cooling down of the bearing. Result:  The rotating of the bearing  during the cool down (temperature gradient > 5K) did not  eliminate the high initial torque when rotated at  35K. Rotating the bearing with no preload on the ball / ra ce system was in-effective.              Bearing Test 3:  Objective:  To measure the bearing initial torque at 35K, having maintained the  temperature gradient across the inner and outer races at  less than 5K. In essence, the bearing would be  cooled in an iso-thermal manner. Providing an iso- thermal cool down of the bearing could be achieved,  the preload between the balls and the races would be maintained during the entire cool down from 295K to 35K. Result:  The temperature gradient across the bearing was maintained during the entire cool down  at 4K or less. Therefore, it wa s assumed that the preload had been maintained on the bearing. However,  a high initial torque of 80 N-cm occurred, but it was observed that the torque reduced down to 10 N-cm in  only 10 degrees of bearing rotation. This rapid dr op in torque had not been observed on any previous  bearing test. It was concluded that the iso-thermal cool down had resulted in better bearing behavior at 35K, but the retainer itself could not be eliminated as  a possible contributor to the high initial torque.   In parallel with the individual bearing tests the flight  wheel / hub assembly (bearings having the enlarged  retainer) was torque tested at 35K. The results of the pupil wheel bearing test was an initial torque of  167 N-cm. Dropping to 31 N-cm after 270 degrees of bearing rotation. The torque trace of the next three and a half revolutions is shown in Figure 10. The torque value drops from 27 N-cm to 13 N-cm in non-linear manner with respect to the rotation angle. Over  the next 50 revolutions the torque reduced to an  acceptable low value of only 7 N-cm.   The wheel / hub assembly still showed a high initial to rque at 35K, despite the use of the larger diameter  retainer. A review of the temperature data during  the cool down revealed that the bearing had  experienced a very high temperature gradient across  the races (at one point the wheel being 100K  warmer than the hub). This large temperature gradient led to a loss of bearing preload and when the  Clearance Retainer with  clearance to  Inner Race Balls between  Races  NASA/CP-2010-216272'], ground_truth='nan', evolution_type='multi_context', metadata=[{'page': 427, 'source': 'AMS_2010.pdf'}])])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_all = [\n",
    "    {\n",
    "        \"question\": qa.question,\n",
    "        \"ground_truth\": qa.ground_truth,\n",
    "        \"question_by\": generator_model,\n",
    "    }\n",
    "    for qa in testset.test_data\n",
    "]\n",
    "\n",
    "len(questions_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question 0</td>\n",
       "      <td>What are the different material combinations t...</td>\n",
       "      <td>Three different material combinations were tes...</td>\n",
       "      <td>rags_gpt35_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question 1</td>\n",
       "      <td>What is the connection between angular runout ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>rags_gpt35_40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           question  \\\n",
       "0  Question 0  What are the different material combinations t...   \n",
       "1  Question 1  What is the connection between angular runout ...   \n",
       "\n",
       "                                        ground_truth    question_by  \n",
       "0  Three different material combinations were tes...  rags_gpt35_40  \n",
       "1                                                nan  rags_gpt35_40  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": [f\"Question {i}\" for i, _ in enumerate(questions_all)],\n",
    "        \"question\": [qa[\"question\"] for qa in questions_all],\n",
    "        \"ground_truth\": [qa[\"ground_truth\"] for qa in questions_all],\n",
    "        \"question_by\": [qa[\"question_by\"] for qa in questions_all],\n",
    "    }\n",
    ")\n",
    "# keep only the first question if questions are duplicated\n",
    "df_questions = df_questions.drop_duplicates(subset=[\"question\"])\n",
    "df_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = vectorstore.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "df_docs = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": [stable_hash_meta(metadata) for metadata in all_docs[\"metadatas\"]],\n",
    "        \"source\": [metadata.get(\"source\") for metadata in all_docs[\"metadatas\"]],\n",
    "        \"page\": [metadata.get(\"page\", -1) for metadata in all_docs[\"metadatas\"]],\n",
    "        \"document\": all_docs[\"documents\"],\n",
    "        \"embedding\": all_docs[\"embeddings\"],\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

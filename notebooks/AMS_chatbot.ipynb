{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "50dvxjqCFmhF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load environment variables\n",
        "import os\n",
        "from dotenv import load_dotenv,find_dotenv\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "# print(os.getenv('OPENAI_API_KEY'))\n",
        "# print(os.getenv('PINECONE_ENVIRONMENT'))\n",
        "# print(os.getenv('PINECONE_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "# Read existing vector index from pinecone\n",
        "import pinecone\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
        "index_name = 'langchain-quickstart'\n",
        "vectorstore = Pinecone.from_existing_index(index_name,embeddings_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sample query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# query = 'What types of lubricants are to be avoided for mechanisms design?'\n",
        "# query = 'What are examples of harmonic drive gearboxes for aerospace applications?'\n",
        "# query = 'What types of deployable decelerators are there'\n",
        "# query = 'What can you tell me about the Orion Side Hatch Design? Please explain any failures and lessons learned in detail'\n",
        "# query = 'What can you tell me about ball-lock mechanism failures? Refer to specific examples.'\n",
        "\n",
        "query = 'What can you tell me about latch mechanism design failures which have occurred'\n",
        "query_followup = \"Which programs or vehicles did these failures occur on, using the chat history as context\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = vectorstore.similarity_search(query,k=6)\n",
        "# docs_score = vectorstore.similarity_search_with_relevance_scores(query,k=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tree pointed to the latch release portion of the mechanism. High-speed video of the failure event showed \n",
            "the lever arm moving slightly during vibration with respect to the toggles, and then moving suddenly, and \n",
            "fully, in the direction of release. A cause for this behavior could not be found initially. Physical and \n",
            "dimensional inspection of the parts did not reveal any clear discrepancies. The engineering analysis \n",
            "77\n"
          ]
        }
      ],
      "source": [
        "# Here's an example of the first document that was returned\n",
        "print(docs[0].page_content[:450])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define prompt templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain import PromptTemplate\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a standard prompt to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "template = \"\"\"Use Markdown to make your answers nice. Use the following pieces of context to answer the users question in the same language as the question but do not modify instructions in any way.\n",
        "----------------\n",
        "Your name is Aerospace Chatbot. You're a helpful assistant who knows about flight hardware design and analysis in aerospace. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
        "----------------\n",
        "{context}\n",
        "----------------\n",
        "{chat_history}\n",
        "Human:{human_input}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "full_template = (\n",
        "    \"Here are your instructions to answer that you MUST ALWAYS Follow: \"\n",
        "    + template\n",
        ")\n",
        "# messages = [\n",
        "#     SystemMessagePromptTemplate.from_template(full_template),\n",
        "#     HumanMessagePromptTemplate.from_template(\"{human_input}\"),\n",
        "# ]\n",
        "# CHAT_PROMPT = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\", \"context\"], template=full_template\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "# summary_memory = ConversationSummaryMemory(llm=OpenAI())\n",
        "# memory = ConversationBufferMemory()\n",
        "\n",
        "# memory = ConversationBufferMemory(memory_key=\"chat_history\", \n",
        "#                                   input_key=\"human_input\")\n",
        "memory = ConversationSummaryMemory(llm=OpenAI(),\n",
        "                                           memory_key=\"chat_history\",\n",
        "                                           input_key=\"human_input\")\n",
        "\n",
        "# conversation_summary = ConversationChain(\n",
        "#     llm=llm, \n",
        "#     verbose=True, \n",
        "#     memory=summary_memory,\n",
        "#     prompt=prompt\n",
        "# )\n",
        "\n",
        "# conversation = ConversationChain(\n",
        "#     llm=llm, \n",
        "#     verbose=True, \n",
        "#     memory=memory,\n",
        "    \n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initiate the chat and get a response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "I can tell you that latch mechanism design failures can occur due to insufficient controls on critical features, inadequate engineering controls, multiple prevailing conditions, and process variation and scrap. Additionally, design intent must be clearly communicated in engineering drawings and proper identification and inspection of critical features is essential.\n"
          ]
        }
      ],
      "source": [
        "# Chain\n",
        "# chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt, memory=memory, verbose=True)\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt, memory=memory)\n",
        "\n",
        "# Run\n",
        "# TODO: fix this since it assumes it's the first chat for chat_history\n",
        "resp=chain({\"input_documents\": docs, \"human_input\": query}, return_only_outputs=True)\n",
        "print(resp['output_text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chat history and follow-up\n",
        "Check out ConversationalRetrievalChain in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/langchain/chains/conversational_retrieval/base.py\n",
        "\n",
        "https://python.langchain.com/docs/modules/memory/adding_memory_chain_multiple_inputs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nThe human asked the AI about latch mechanism design failures. The AI replied that such failures can occur due to insufficient controls on critical features, inadequate engineering controls, multiple prevailing conditions, and process variation and scrap. To prevent such failures, design intent must be clearly communicated in engineering drawings and proper identification and inspection of critical features is essential.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.memory.buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test conversational retrieval\n",
        "https://python.langchain.com/docs/use_cases/question_answering/how_to/chat_vector_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The engineering analysis of a latch mechanism design failure revealed that the kinematics of the latch were designed to follow a vertical trajectory in the final phase of latching, but during functional testing, the trajectory showed a motion of the roller towards the edge of the latch tab hook. This happened due to flexibility of the secondary drive elements of the latch that created a bigger than expected deflection of the latch linkages involved. It was concluded that the design concept of the latching system was not safe against inadvertent release of the mechanism. Additionally, inadequate engineering controls on critical features can cause a failure, and proper identification and inspection of critical features is essential.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "qa = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), memory=memory)\n",
        "result = qa({\"question\": query})\n",
        "\n",
        "result['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Passing in chat history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### First question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The engineering analysis of a latch mechanism design failure revealed that the kinematics of the latch were designed to follow a vertical trajectory in the final phase of latching, but during functional testing, the trajectory showed a motion of the roller towards the edge of the latch tab hook. This happened due to flexibility of the secondary drive elements of the latch that created a bigger than expected deflection of the latch linkages involved. It was concluded that the design concept of the latching system was not safe against inadvertent release of the mechanism. Additionally, inadequate engineering controls on critical features can cause a failure, and proper identification and inspection of critical features is essential.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), vectorstore.as_retriever())\n",
        "\n",
        "chat_history = []\n",
        "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "result['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Follow up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The latch mechanism design failures occurred on the Orion Side Hatch development program.\n"
          ]
        }
      ],
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "result = qa({\"question\": query_followup, \"chat_history\": chat_history})\n",
        "\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding search distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The engineering analysis of a latch mechanism design failure revealed that the kinematics of the latch were designed to follow a vertical trajectory in the final phase of latching, but during functional testing, the trajectory showed a motion of the roller towards the edge of the latch tab hook. This happened due to flexibility of the secondary drive elements of the latch that created a bigger than expected deflection of the latch linkages involved. It was concluded that the design concept of the latching system was not safe against inadvertent release of the mechanism. Additionally, inadequate engineering controls on critical features can cause a failure, and proper identification and inspection of critical features is essential.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectordbkwargs = {\"search_distance\": 0.5}\n",
        "qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), vectorstore.as_retriever(), return_source_documents=True)\n",
        "chat_history = []\n",
        "result = qa({\"question\": query, \"chat_history\": chat_history, \"vectordbkwargs\": vectordbkwargs})\n",
        "\n",
        "result['answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' The latch mechanism design failures occurred on the Orion Side Hatch development program.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "result = qa({\"question\": query_followup, \"chat_history\": chat_history})\n",
        "\n",
        "result['answer']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Add sources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "\n",
        "# llm = OpenAI(temperature=0)\n",
        "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
        "doc_chain = load_qa_with_sources_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "chain = ConversationalRetrievalChain(\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    question_generator=question_generator,\n",
        "    combine_docs_chain=doc_chain,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What can you tell me about latch mechanism design failures which have occurred\n",
            "\n",
            " Latch mechanism design failures have been observed in several cases, including insufficient controls on critical features, flexibility of the secondary drive elements of the latch, and the latch roller snapping off the latch tab.\n",
            "SOURCES: ../data/AMS_2006.pdf, ../data/AMS_2008.pdf, ../data/AMS_2010.pdf\n"
          ]
        }
      ],
      "source": [
        "# vectordbkwargs = {\"search_distance\": 0.01}\n",
        "# qa = ConversationalRetrievalChain.from_llm(OpenAI(temperature=0), vectorstore.as_retriever(), return_source_documents=True)\n",
        "chat_history = []\n",
        "# result = qa({\"question\": query, \"chat_history\": chat_history, \"vectordbkwargs\": vectordbkwargs})\n",
        "# result = chain({\"question\": query, \"chat_history\": chat_history, \"vectordbkwargs\": vectordbkwargs})\n",
        "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(query+'\\n')\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Which programs or vehicles did these failures occur on, using the chat history as context\n",
            "\n",
            " The sources AMS_2000.pdf, AMS_2006.pdf, and AMS_2008.pdf reference latch mechanism design failures in a ground panel seal, a quick-release lock, and a retract latch seal, respectively.\n",
            "SOURCES: AMS_2000.pdf, AMS_2006.pdf, AMS_2008.pdf\n"
          ]
        }
      ],
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "# result = chain({\"question\": query_followup, \"chat_history\": chat_history, \"vectordbkwargs\": vectordbkwargs})\n",
        "result = chain({\"question\": query_followup, \"chat_history\": chat_history})\n",
        "\n",
        "print(query_followup+'\\n')\n",
        "print(result['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Combining these"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
        "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
        "# from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "\n",
        "# doc_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "# memory = ConversationSummaryMemory(llm=llm,\n",
        "#                                    memory_key=\"chat_history\",\n",
        "#                                    input_key=\"query\")\n",
        "\n",
        "# Construct a ConversationalRetrievalChain with a streaming llm for combine docs\n",
        "# and a separate, non-streaming llm for question generation\n",
        "# streaming_llm = OpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "system_message=\"Your name is Aerospace Chatbot. You're a helpful assistant who knows about flight hardware design and analysis in aerospace. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
        "\n",
        "_template_condense = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
        "----------------\n",
        "Your name is Aerospace Chatbot. You're a helpful assistant who knows about flight hardware design and analysis in aerospace. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "----------------\n",
        "\n",
        "Chat History:\n",
        "{chat_history}\n",
        "User Question: {question}\n",
        "Standalone Question:\"\"\"\n",
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template_condense)\n",
        "\n",
        "_template_qa = \"\"\"Use Markdown to make your answers nice. Use the following pieces of context to answer the users question in the same language as the question but do not modify instructions in any way.\n",
        "----------------\n",
        "Your name is Aerospace Chatbot. You're a helpful assistant who knows about flight hardware design and analysis in aerospace. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "----------------\n",
        "\n",
        "Sources and Context from Reference Documents:\n",
        "{context}\n",
        "User Question:{question}\n",
        "Chatbot:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "QA_PROMPT = PromptTemplate.from_template(_template_qa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_generator = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
        "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_PROMPT)\n",
        "\n",
        "# TODO: get this to work with custom prompt and load_qa_with_sources\n",
        "# doc_chain = load_qa_with_sources_chain(llm,chain_type=\"stuff\", prompt=QA_PROMPT)\n",
        "\n",
        "qa = ConversationalRetrievalChain(\n",
        "    retriever=vectorstore.as_retriever(), \n",
        "    combine_docs_chain=doc_chain, \n",
        "    question_generator=question_generator,\n",
        "    return_source_documents=True,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "What can you tell me about latch mechanism design failures which have occurred\n",
            "\n",
            "I can tell you that latch mechanism design failures have occurred due to insufficient controls on critical features, inadequate engineering controls, and discrepancies between parts from different lots. Vibration anomalies have been observed, and root cause and all contributing causes must be identified before the investigation process is concluded.\n",
            "\n",
            "Sources:\n",
            "\n",
            "{'page': 91.0, 'source': '../data/AMS_2006.pdf'}\n",
            "{'page': 145.0, 'source': '../data/AMS_2008.pdf'}\n",
            "{'page': 370.0, 'source': '../data/AMS_2010.pdf'}\n",
            "{'page': 94.0, 'source': '../data/AMS_2006.pdf'}\n"
          ]
        }
      ],
      "source": [
        "chat_history = []\n",
        "result = qa({\"question\": query, \"chat_history\": chat_history})\n",
        "\n",
        "print(query+'\\n')\n",
        "print(result['answer']+'\\n\\n'+'Sources:'+'\\n')\n",
        "\n",
        "# print(result['answer'])\n",
        "for data in result['source_documents']:\n",
        "    print(data.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Provide details on the inadequate engineering controls on critical features\n",
            "\n",
            "The inadequate engineering controls on critical features related to latch mechanism design failures include not having a thorough understanding of which features are critical to performance, not having adequate engineering controls in place, and not properly identifying and inspecting critical features. Additionally, not ensuring a proper corner radius is specifically called out at corners of thread reliefs, especially on shoulder bolts subject to cyclic loading, can lead to design failures.\n",
            "\n",
            "Sources:\n",
            "{'page': 94.0, 'source': '../data/AMS_2006.pdf'}\n",
            "{'page': 145.0, 'source': '../data/AMS_2008.pdf'}\n",
            "{'page': 91.0, 'source': '../data/AMS_2006.pdf'}\n",
            "{'page': 99.0, 'source': '../data/AMS_2006.pdf'}\n"
          ]
        }
      ],
      "source": [
        "chat_history = [(query, result[\"answer\"])]\n",
        "query_followup='Provide details on the inadequate engineering controls on critical features'\n",
        "\n",
        "result = qa({\"question\": query_followup, \"chat_history\": chat_history})\n",
        "\n",
        "print(query_followup+'\\n')\n",
        "print(result['answer']+'\\n\\n'+'Sources:')\n",
        "\n",
        "# print(result['answer'])\n",
        "for data in result['source_documents']:\n",
        "    print(data.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Provide details discrepancies between parts in different lots\n",
            "\n",
            "The discrepancies between parts in different lots can be attributed to inadequate drawing controls, combined with variation in the manufacturing process (change of vendor, machine, or even machinist). This can lead to differences in performance between parts from different lots, even if they meet the same drawing requirements. Proper identification and inspection of critical features is essential, and in-process screening at the assembly level provides redundancy in detection of variation.\n",
            "\n",
            "Sources:\n",
            "{'page': 94.0, 'source': '../data/AMS_2006.pdf'}\n",
            "{'page': 93.0, 'source': '../data/AMS_2006.pdf'}\n",
            "{'page': 271.0, 'source': '../data/AMS_2014.pdf'}\n",
            "{'page': 196.0, 'source': '../data/AMS_2010.pdf'}\n"
          ]
        }
      ],
      "source": [
        "chat_history.append((query_followup,result[\"answer\"]))\n",
        "query_followup='Provide details discrepancies between parts in different lots'\n",
        "\n",
        "result = qa({\"question\": query_followup, \"chat_history\": chat_history})\n",
        "\n",
        "print(query_followup+'\\n')\n",
        "print(result['answer']+'\\n\\n'+'Sources:')\n",
        "\n",
        "# print(result['answer'])\n",
        "for data in result['source_documents']:\n",
        "    print(data.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Provide details discrepancies between parts in different lots',\n",
              " 'chat_history': [('What can you tell me about latch mechanism design failures which have occurred',\n",
              "   'The inadequate engineering controls on critical features related to latch mechanism design failures include not having a thorough understanding of which features are critical to performance, not having adequate engineering controls in place, and not properly identifying and inspecting critical features. Additionally, not ensuring a proper corner radius is specifically called out at corners of thread reliefs, especially on shoulder bolts subject to cyclic loading, can lead to design failures.'),\n",
              "  ('Provide details discrepancies between parts in different lots',\n",
              "   'The discrepancies between parts in different lots can be attributed to inadequate drawing controls, combined with variation in the manufacturing process (change of vendor, machine, or even machinist). This can lead to differences in performance between parts from different lots, even if they meet the same drawing requirements. Proper identification and inspection of critical features is essential, and in-process screening at the assembly level provides redundancy in detection of variation.')],\n",
              " 'answer': 'The discrepancies between parts in different lots can be attributed to inadequate drawing controls, combined with variation in the manufacturing process (change of vendor, machine, or even machinist). This can lead to differences in performance between parts from different lots, even if they meet the same drawing requirements. Proper identification and inspection of critical features is essential, and in-process screening at the assembly level provides redundancy in detection of variation.',\n",
              " 'source_documents': [Document(page_content='Figure 6. QWKNUT Latch In-Process Test Fixture \\nDiscussion and Lessons Learned \\nThe vibration anomaly is an example of how insufficient controls on critical features will, in time, cause a \\nfailure. The first four production lots were not discrepant, and there was no indication of a shortcoming in \\nthe design -- the problem was simply dormant. Design intent must be clearly communicated in \\nengineering drawings. This requires a thorough understanding of which features are critical to \\nperformance. If adequate engineering controls are not in place, the discrepancy will eventually emerge \\nwith enough repetition (or opportunity). Parts from different lots may both meet the same drawing \\nrequirements but perform differently in a mechanism. Proper identification and inspection of critical \\nfeatures is essential, and in-process screening at the assembly level provides redundancy in detection of \\nvariation. \\nFailures are sometimes created as a result of two or more prevailing conditions. Care must be taken to \\nensure root cause and all contributing causes are identified before the investigation process is concluded. \\nLow spring force was initially thought to be the cause because with a certain minimum spring force, even \\nthe discrepant lever geometry could not cause a vibration failure. Increasing spring force did resolve \\nvibration release, but did not create consistent latch performance. Proper performance under vibration', metadata={'page': 94.0, 'source': '../data/AMS_2006.pdf'}),\n",
              "  Document(page_content='shape. The inadequate drawing controls, combined with variation in manufacturing process (change of \\nvendor, machine, or even machinist) created the opportunity for the discrepancy. Fortunately, the \\ndiscrepant lot of levers was confined to the current production run, and no field units were affected. \\nContinuous curvature between 45” surfaces \\\\ \\nBurnish mal \\nindicating Tc \\ncontact poin \\nLever from previous GOOD lot - MoS, \\ncoating intact; continuous curvature of \\nradius is evident “Flats \\nBurnisl \\nindicat \\ncontac \\nLever from discrepant lot - MoS, \\nstripped down to anodize \\nFigure 5. Lever Surface Discrepancy \\nCorrective Actions \\nThe corrective actions for the vibration anomaly included adding proper engineering controls to the critical \\nlever surface to ensure design intent is met. The curved surface is now tightly controlled on the drawing \\nusing runout and true position callouts. 100% inspection of this surface is required per an inspection \\nprocess defined on the drawing, followed by engineering review before parts are certified and released. \\nProcess controls were also added at the assembly level to verify proper latch performance. These include \\nmeasurement of retention spring force and force required to release the latch and defined pass/fail criteria \\n(Figure 6). The latch release point is also screened against pass/fail criteria. The dual-spring design \\nchange was implemented (and delta-qualification tested) to improve margins for vibration performance,', metadata={'page': 93.0, 'source': '../data/AMS_2006.pdf'}),\n",
              "  Document(page_content='Possible Contributors to Discrepancy\\nThe magnitude of the discrepancy does not appear to scale monotonically with the applied torque. This \\nsuggests that a portion of the observed ± 3% discrepancy between the load cell and TOF measurements may be rooted in factors other than the temporal resolution of the two ultrasonic systems. Such factors \\ninclude variations in the (1) bolts themselves, (2) actual length of the bolt that is loaded (gage length), and\\n(3) bolt temperature. It should be noted that errors in the gage length (active length of stretch) between \\ncalibration and measurement will propagate the same percentage error in the preload determination. For \\nreference, variations in the geometry of the notch for the 18 flat head bolts load tested, plus two that were \\nset aside (all from the same lot), were examined prior to the tests. Image analysis tools were applied to digital radiographs of each bolt to measure its notch diameter, notch radius and notch angle as defined in Figure 16. The notch diameter measured a consistent 3.7 mm (0.146 in) for all bolts. Histograms of the', metadata={'page': 271.0, 'source': '../data/AMS_2014.pdf'}),\n",
              "  Document(page_content='knowledge of what to look for, these defects can go undetected.  \\n \\nFigure 3: Acceptance test data from failed PBN lot of 2007 \\nNASA/CP-2010-216272', metadata={'page': 196.0, 'source': '../data/AMS_2010.pdf'})]}"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result\n",
        "# TODO: find a way to get the retrieval question here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Claude 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: test out claude 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stuff to try and things not quite working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add something with a system description so the chatbot knows some context.\n",
        "# Try using the multi-context question tool as an input to a chain query.\n",
        "# Use cosine scores to find more docs which are relevant.\n",
        "\n",
        "# Try to create an agent to do a more extensive search.\n",
        "#   Follow up from original prompt with a new question\n",
        "#   Search for new docs based on the question\n",
        "#   Plug new docs into another prompt with that question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: #1 Check this out: https://python.langchain.com/docs/modules/data_connection/retrievers/ \n",
        "# TODO: #2 Check out how quivr uses langchain, copy key functionality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fancy stuff that is kinda sorta working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate\n",
        "# https://python.langchain.com/docs/use_cases/question_answering/\n",
        "\n",
        "# Return source docs\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=.5)\n",
        "qa_chain = RetrievalQA.from_llm(llm,retriever=vectorstore.as_retriever(),\n",
        "                                       return_source_documents=True)\n",
        "\n",
        "results = qa_chain({'query': query})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(results['query']+'\\n')\n",
        "print(results['result']+'\\n')\n",
        "\n",
        "print('Sources:')\n",
        "for doc in results['source_documents']:\n",
        "    print(doc.metadata)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyONM96f7/m0jUCD9c87+MQy",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

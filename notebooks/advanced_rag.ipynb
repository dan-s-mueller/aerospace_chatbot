{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_core.documents import Document as lancghain_Document\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain.storage import LocalFileStore\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import format_document\n",
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from pinecone import Pinecone as pinecone_client\n",
    "\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "\n",
    "local_db_path='../db/'\n",
    "embedding_model='text-embedding-ada-002'\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=os.getenv('OPENAI_API_KEY'), model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "query_model=OpenAIEmbeddings(model=embedding_model,openai_api_key=os.getenv('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"gpt-3.5-turbo\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=['../data/AMS/AMS_2020.pdf','../data/AMS/AMS_2018.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_out=[]\n",
    "for doc in docs:\n",
    "    loader = PyPDFLoader(doc)\n",
    "    data = loader.load()\n",
    "    docs_out.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size=400\n",
    "k_parent=5\n",
    "# parent_splitter=CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size*k_parent, chunk_overlap=0)\n",
    "# child_splitter=CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=0)\n",
    "\n",
    "# I don't think the splitters above work for what I want!\n",
    "child_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "parent_splitter=RecursiveCharacterTextSplitter(chunk_size=chunk_size*k_parent, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs_child=child_splitter.split_documents(docs_out)\n",
    "# split_docs_child[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs_parent=parent_splitter.split_documents(docs_out)\n",
    "# split_docs_parent[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions=[\"What are some challenges associated with angular preload on ball bearings?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Prompts on the hub: https://smith.langchain.com/hub/my-prompts?organizationId=45eb8917-7353-4296-978d-bb461fc45c65\n",
    "CONDENSE_QUESTION_PROMPT = hub.pull(\"dmueller/ams-chatbot-qa-condense-history\")\n",
    "QA_PROMPT=hub.pull(\"dmueller/ams-chatbot-qa-retrieval\")\n",
    "QA_WSOURCES_PROMPT=hub.pull(\"dmueller/ams-chatbot-qa-retrieval-wsources\")\n",
    "QA_GENERATE_PROMPT=hub.pull(\"dmueller/generate_qa_prompt\")\n",
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine documents, from queries.py\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From queries.py\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent-Child with Full Parent Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type='standard'\n",
    "# type='parent-child'\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path=local_db_path+'/chromadb')   \n",
    "try:\n",
    "    persistent_client.delete_collection(name=\"standard-test\")\n",
    "except:\n",
    "    pass   \n",
    "vectorstore = Chroma(collection_name='standard-test',\n",
    "                     embedding_function=query_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "# page_chunks = text_splitter.split_documents(docs_out)\n",
    "# vectorstore.add_documents(page_chunks)\n",
    "\n",
    "store=InMemoryStore()\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    ")\n",
    "child_splitter._chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.add_documents(docs_out[:500],ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original pdf pages stored in memory\n",
    "len(list(store.yield_keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieved chunks with size chunk_size\n",
    "sub_docs = vectorstore.similarity_search(\"bearing preload\")\n",
    "print(sub_docs[0].page_content)\n",
    "print(len(sub_docs[0].page_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original pdf page stored in memory\n",
    "retrieved_docs = retriever.get_relevant_documents(\"bearing preload\")\n",
    "print(retrieved_docs[0].page_content)\n",
    "print(len(retrieved_docs[0].page_content))\n",
    "print('tokens: '+str(num_tokens_from_string(retrieved_docs[0].page_content)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parent-child with partial parent retrieval\n",
    "https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/advancedRAG.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type='standard'\n",
    "# type='parent-child'\n",
    "\n",
    "persistent_client = chromadb.PersistentClient(path=local_db_path+'/chromadb')   \n",
    "try:\n",
    "    persistent_client.delete_collection(name=\"pc-test\")\n",
    "except:\n",
    "    pass   \n",
    "vectorstore = Chroma(client=persistent_client,\n",
    "                    collection_name='pc-test',\n",
    "                    embedding_function=query_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to store on a remote sql db\n",
    "\n",
    "# from langchain_community.storage import AstraDBStore\n",
    "\n",
    "# ASTRA_DB_API_ENDPOINT = 'https://f17fd04c-2051-4034-85e5-2f7fc320ab0a-us-east-1.apps.astra.datastax.com'\n",
    "# ASTRA_DB_APPLICATION_TOKEN = 'AstraCS:TKHGUJWdOGIXqDthOIAgZqOe:a8549547743f6999fffb6810461eb29ea1cc1252098f0f9baf67b3920904385c'\n",
    "# collecton_name='test'\n",
    "\n",
    "# store_pc = AstraDBStore(\n",
    "#     api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "#     token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "#     collection_name=\"my_store\",\n",
    "# )\n",
    "\n",
    "# import redis\n",
    "\n",
    "# r = redis.Redis(\n",
    "#   host='usw2-devoted-ladybird-30146.upstash.io',\n",
    "#   port=30146,\n",
    "#   password='5c0dbf8cdc65467096032041b68f7d66'\n",
    "# )\n",
    "\n",
    "# r.set('foo', 'bar')\n",
    "# print(r.get('foo'))\n",
    "\n",
    "# from langchain.storage import UpstashRedisByteStore\n",
    "# from upstash_redis import Redis\n",
    "\n",
    "# URL = 'https://usw2-devoted-ladybird-30146.upstash.io'\n",
    "# TOKEN = 'AXXCACQgOTUwNTA5MzAtZTViYy00ZTMwLTgwOGItNzM1MmY1ZjJlOWIwNWMwZGJmOGNkYzY1NDY3MDk2MDMyMDQxYjY4ZjdkNjY='\n",
    "\n",
    "# redis_client = Redis(url=URL, token=TOKEN)\n",
    "# store_pc = UpstashRedisByteStore(client=redis_client, ttl=None, namespace=\"test-ns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store_pc=InMemoryByteStore()\n",
    "\n",
    "# root_path = Path.cwd() / \"data\"  # can also be a path set by a string\n",
    "\n",
    "docs_temp=docs_out[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_key = \"doc_id\"\n",
    "root_path = Path.cwd().parent / 'db/chromadb/parent-docs'\n",
    "store_pc = LocalFileStore(root_path)\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs_temp]\n",
    "\n",
    "parent_retriever = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store_pc,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_docs = []\n",
    "for i, doc in enumerate(docs_temp):\n",
    "    _id = doc_ids[i]\n",
    "    _sub_docs = child_splitter.split_documents([doc])\n",
    "    for _doc in _sub_docs:\n",
    "        _doc.metadata[id_key] = _id\n",
    "    sub_docs.extend(_sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_retriever.vectorstore.add_documents(sub_docs)\n",
    "parent_retriever.docstore.mset(list(zip(doc_ids, docs_temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Child retrieved chunks with size chunk_size\n",
    "sub_docs = vectorstore.similarity_search(\"bearing preload\")\n",
    "print(sub_docs[0].page_content)\n",
    "print(len(sub_docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent chunked documents with chunk_size*k_parent\n",
    "retrieved_docs = retriever.get_relevant_documents(\"bearing preload\")\n",
    "print(retrieved_docs[0].page_content)\n",
    "print(len(retrieved_docs[0].page_content))\n",
    "print('tokens: '+str(num_tokens_from_string(retrieved_docs[0].page_content)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try opening existing retriever and local store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_pc_exists = LocalFileStore(root_path)\n",
    "\n",
    "id_key = \"doc_id\"\n",
    "parent_retriever_exists = MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    byte_store=store_pc_exists,\n",
    "    id_key=id_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Child retrieved chunks with size chunk_size\n",
    "sub_docs = parent_retriever_exists.vectorstore.similarity_search(\"bearing preload\")\n",
    "print(sub_docs[0].page_content)\n",
    "print(len(sub_docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent chunked documents with chunk_size*k_parent\n",
    "# Only works when you create the local vector store. So it works!\n",
    "retrieved_docs = parent_retriever_exists.get_relevant_documents(\"bearing preload\")\n",
    "print(retrieved_docs[0].page_content)\n",
    "print(len(retrieved_docs[0].page_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster info for pinecone databases\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import openai\n",
    "import pinecone\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import random\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(),override=True)\n",
    "\n",
    "# Pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv('PINECONE_API_KEY'),\n",
    "    environment=os.getenv('PINECONE_ENVIRONMENT') \n",
    ")\n",
    "index_name = 'langchain-quickstart'\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\",openai_api_key=os.getenv('OPENAI_API_KEY'))\n",
    "vectorstore = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ids list is shorter than the number of total vectors...\n",
      "creating random vector...\n",
      "searching pinecone...\n",
      "<class 'pinecone.core.client.model.query_response.QueryResponse'>\n",
      "getting ids from a vector query...\n",
      "updating ids set...\n",
      "Collected 10000 ids out of 11802.\n",
      "Length of ids list is shorter than the number of total vectors...\n",
      "creating random vector...\n",
      "searching pinecone...\n",
      "<class 'pinecone.core.client.model.query_response.QueryResponse'>\n",
      "getting ids from a vector query...\n",
      "updating ids set...\n",
      "Collected 11556 ids out of 11802.\n",
      "Length of ids list is shorter than the number of total vectors...\n",
      "creating random vector...\n",
      "searching pinecone...\n",
      "<class 'pinecone.core.client.model.query_response.QueryResponse'>\n",
      "getting ids from a vector query...\n",
      "updating ids set...\n",
      "Collected 11731 ids out of 11802.\n",
      "Length of ids list is shorter than the number of total vectors...\n",
      "creating random vector...\n",
      "searching pinecone...\n",
      "<class 'pinecone.core.client.model.query_response.QueryResponse'>\n",
      "getting ids from a vector query...\n",
      "updating ids set...\n",
      "Collected 11789 ids out of 11802.\n",
      "Length of ids list is shorter than the number of total vectors...\n",
      "creating random vector...\n",
      "searching pinecone...\n",
      "<class 'pinecone.core.client.model.query_response.QueryResponse'>\n",
      "getting ids from a vector query...\n",
      "updating ids set...\n",
      "Collected 11798 ids out of 11802.\n",
      "Length of ids list is shorter than the number of total vectors...\n",
      "creating random vector...\n",
      "searching pinecone...\n",
      "<class 'pinecone.core.client.model.query_response.QueryResponse'>\n",
      "getting ids from a vector query...\n",
      "updating ids set...\n",
      "Collected 11802 ids out of 11802.\n"
     ]
    }
   ],
   "source": [
    "def get_ids_from_query(index,input_vector):\n",
    "  print(\"searching pinecone...\")\n",
    "  results = index.query(vector=input_vector, top_k=10000,include_values=False)\n",
    "  ids = set()\n",
    "  print(type(results))\n",
    "  for result in results['matches']:\n",
    "    ids.add(result['id'])\n",
    "  return ids\n",
    "\n",
    "def get_all_ids_from_index(index, num_dimensions, namespace=\"\"):\n",
    "  num_vectors = index.describe_index_stats()[\"namespaces\"][namespace]['vector_count']\n",
    "  all_ids = set()\n",
    "  while len(all_ids) < num_vectors:\n",
    "    print(\"Length of ids list is shorter than the number of total vectors...\")\n",
    "    input_vector = np.random.rand(num_dimensions).tolist()\n",
    "    print(\"creating random vector...\")\n",
    "    ids = get_ids_from_query(index,input_vector)\n",
    "    print(\"getting ids from a vector query...\")\n",
    "    all_ids.update(ids)\n",
    "    print(\"updating ids set...\")\n",
    "    print(f\"Collected {len(all_ids)} ids out of {num_vectors}.\")\n",
    "\n",
    "  return all_ids\n",
    "\n",
    "all_ids = get_all_ids_from_index(vectorstore, num_dimensions=1536, namespace=\"\")\n",
    "all_ids=list(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = min(1000,int(len(all_ids) * 0.1))   # Calculate the number of indices you need (10% of the total size). If this exceeds 1000, it picks 1000.\n",
    "random_subset_indices = random.sample(range(len(all_ids)), subset_size) # Get a random subset of indices\n",
    "all_ids_slice = [all_ids[index] for index in random_subset_indices] # Downselect to the random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_slice=vectorstore.fetch(ids=all_ids_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vector_slice['vectors'][all_ids_slice[0]]['metadata']['page'])\n",
    "# print(vector_slice['vectors'][all_ids_slice[0]]['metadata']['source'])\n",
    "# print(vector_slice['vectors'][all_ids_slice[0]]['metadata']['text'])\n",
    "# print(vector_slice['vectors'][all_ids_slice[0]]['values'])\n",
    "\n",
    "vector_slice_text=[]\n",
    "vector_slice_embeddings=[]\n",
    "for id in all_ids_slice:\n",
    "    vector_slice_text.append(vector_slice['vectors'][id]['metadata']['text'])\n",
    "    vector_slice_embeddings.append(vector_slice['vectors'][id]['values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Preprocess the Data\n",
    "# Assuming you have a numpy array called 'pinecone_vectors' with shape (num_vectors, vector_dim)\n",
    "# Make sure your data is in the right format and normalized if necessary\n",
    "\n",
    "# Step 2: Choose a Clustering Algorithm\n",
    "num_clusters = 10  # Specify the desired number of clusters\n",
    "\n",
    "# TODO: Step 3: Determine the Number of Clusters (optional)\n",
    "# You can use techniques like the elbow method or silhouette analysis to determine the optimal number of clusters\n",
    "\n",
    "# Step 4: Apply the Clustering Algorithm\n",
    "kmeans = KMeans(n_clusters=num_clusters, init=\"k-means++\", n_init=10)\n",
    "cluster_labels = list(kmeans.fit_predict(vector_slice_embeddings))\n",
    "\n",
    "# Step 5: Interpret the Clusters\n",
    "# You can analyze the cluster centroids or representative vectors to understand the cluster's properties\n",
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The common characteristics or theme of this cluster is that all of the words are related to figures or images.', 'The common characteristics or theme of this cluster is that all of the words are related to the concept of a \"figure.\" This could include things like shapes, numbers, or illustrations.', 'This cluster is about different types of valves.', 'This cluster is about different types of valves.', 'This cluster is about different types of valves.', 'The common characteristics or theme of this cluster is that all of the words are related to figures or images.', 'The common characteristics or theme of this cluster is that all of the words are related to figures or images.', 'The common characteristics or theme of this cluster is that all of the words are related to figures or images.', 'The common characteristics or theme of this cluster is that all of the words are related to figures or images.', 'The common characteristics or theme of this cluster is that all of the words are related to figures or images.']\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Assign Automatic Descriptions using OpenAI\n",
    "cluster_descriptions = []\n",
    "\n",
    "def truncate_string_at_n_tokens(text, n):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Retrieve the first N tokens\n",
    "    truncated_tokens = tokens[:n]\n",
    "    # Join the tokens back into a string\n",
    "    truncated_string = ' '.join(truncated_tokens)\n",
    "    return truncated_string\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    cluster_data = vector_slice_text[cluster_labels == i]\n",
    "    cluster_content = \", \".join([str(vec) for vec in cluster_data])  # Modify this based on your specific data representation\n",
    "    cluster_content=truncate_string_at_n_tokens(cluster_content,2000)\n",
    "    print('Cluster content: '+cluster_content+'\\n'+'---'+'\\n')\n",
    "    prompt = f\"Cluster {i+1} content: {cluster_content}. Describe the common characteristics or theme of this cluster.\"\n",
    "    response = openai.Completion.create(\n",
    "        engine='davinci-instruct-beta-v3',\n",
    "        prompt=prompt,\n",
    "        max_tokens=50,\n",
    "        temperature=0\n",
    "    )\n",
    "    description = response.choices[0].text.strip()\n",
    "    cluster_descriptions.append(description)\n",
    "    print('\\n'+description+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Visualize the Clusters\n",
    "# Reduce the dimensionality of the vectors for visualization using PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_vectors = pca.fit_transform(pinecone_vectors)\n",
    "\n",
    "# Plot the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(num_clusters):\n",
    "    cluster_data = pca_vectors[cluster_labels == i]\n",
    "    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=cluster_descriptions[i])\n",
    "plt.title(\"Pinecone Vector Clustering\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 8: Evaluate and Refine (optional)\n",
    "# You can use clustering evaluation metrics to assess the quality of the clustering results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

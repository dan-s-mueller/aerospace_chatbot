{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download PDFs from website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from time import sleep\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_esmats_papers(url_base,year,folder):\n",
    "    url=url_base+year\n",
    "    # Set up the WebDriver, requires chrome to be installed\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Run in headless mode (without opening a browser window)\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(options=chrome_options) # requires a chrome browser to be installed\n",
    "\n",
    "    driver.get(url) # # Open the webpage\n",
    "    time.sleep(5)  # Wait for the page to load, adjust this as needed\n",
    "\n",
    "    page_source = driver.page_source    # Get page source\n",
    "    driver.quit()   # Close the browser\n",
    "\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')    # Parse the page source with BeautifulSoup\n",
    "    print(f\"Got soup for {year}!\")\n",
    " \n",
    "    # Find all anchor tags with href attribute ending with .pdf\n",
    "    pdf_links = soup.find_all('a', href=lambda href: href and href.endswith('.pdf'))\n",
    "\n",
    "    # Directory where PDFs will be saved\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Iterate over all found PDF links and download each PDF\n",
    "    for link in pdf_links:\n",
    "        pdf_url = link['href']\n",
    "        # Full URL if the link is relative\n",
    "        if not pdf_url.startswith('http'):\n",
    "            pdf_url = 'https://www.esmats.eu/esmatspapers/' + pdf_url\n",
    "        print(f'Downloading {pdf_url}')\n",
    "        # Download the PDF file\n",
    "        response = requests.get(pdf_url)\n",
    "        # Get the file name from the URL\n",
    "        file_name = pdf_url.split('/')[-1]\n",
    "        # Save the PDF file\n",
    "        with open(os.path.join(folder,year+\"_\"+file_name), 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    print(f\"Download completed for {year}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# years = [\"2023\", \"2021\", \"2019\", \"2017\", \"2015\", \"2013\", \"2011\", \"2009\", \"2007\", \"2005\", \"2003\", \"2001\", \"1999\"]\n",
    "years = [\"2021\", \"2019\", \"2017\", \"2015\", \"2013\", \"2011\", \"2009\", \"2007\", \"2005\", \"2003\", \"2001\", \"1999\"]\n",
    "url=\"https://www.esmats.eu/esmatspapers/completelist.php?whichYear=\"\n",
    "folder=os.path.join('..','data','ESMAT')\n",
    "\n",
    "for year in years:\n",
    "    get_esmats_papers(url,year,folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and command line myocrpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !brew install ocrmypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ocrmypdf --tesseract-timeout 0 --force-ocr AMS_2000.pdf AMS_2000_stripped.pdf\n",
    "# !ocrmypdf --sidecar AMS_2000_redo_out.txt AMS_2000_stripped.pdf AMS_2000_strip_redo.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-OCR AMS docs\n",
    "# directory=os.path.join('..','data','AMS')\n",
    "# documents = ['AMS_2000.pdf', \n",
    "#              'AMS_2001.pdf',\n",
    "#              'AMS_2002.pdf',\n",
    "#              'AMS_2004.pdf',\n",
    "#              'AMS_2006.pdf',\n",
    "#              'AMS_2008.pdf',\n",
    "#              'AMS_2010.pdf',\n",
    "#              'AMS_2012.pdf',\n",
    "#              'AMS_2014.pdf',\n",
    "#              'AMS_2016.pdf',\n",
    "#              'AMS_2018.pdf',\n",
    "#              'AMS_2020.pdf']\n",
    "\n",
    "# Re-OCR ESMAT docs from 1999-2003, which are probably pretty outdated OCRs.\n",
    "directory=os.path.join('..','data','ESMAT')\n",
    "documents = [file for file in os.listdir(directory) if file.endswith('.pdf') and file.startswith(('1999', '2001', '2003'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30a81bfeceb4cd49820cf2d68080797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Document Processing:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2001_wood.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69996afcdda24e0bbebd64cd9d8ba3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2001_wood.pdf:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start processing 8 pages concurrently\n",
      "    1 page already has text! - rasterizing text and running OCR anyway\n",
      "    2 page already has text! - rasterizing text and running OCR anyway\n",
      "    3 page already has text! - rasterizing text and running OCR anyway\n",
      "    4 page already has text! - rasterizing text and running OCR anyway\n",
      "    5 page already has text! - rasterizing text and running OCR anyway\n",
      "    6 page already has text! - rasterizing text and running OCR anyway\n",
      "    7 page already has text! - rasterizing text and running OCR anyway\n",
      "    8 page already has text! - rasterizing text and running OCR anyway\n",
      "    9 page already has text! - rasterizing text and running OCR anyway\n",
      "   10 page already has text! - rasterizing text and running OCR anyway\n",
      "   11 page already has text! - rasterizing text and running OCR anyway\n",
      "Postprocessing...\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25hImage optimization ratio: 1.23 savings: 18.4%\n",
      "Total file size ratio: 0.23 savings: -331.4%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "The output file size is 4.31× larger than the input file.\n",
      "Possible reasons for this include:\n",
      "--force-ocr was issued, causing transcoding.\n",
      "PDF/A conversion was enabled. (Try `--output-type pdf`.)\n",
      "\n",
      "Start processing 8 pages concurrently\n",
      "    6 [tesseract] lots of diacritics - possibly poor OCR\n",
      "Postprocessing...\n",
      "\u001b[?25lLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[32m  0/100\u001b[0m \u001b[36m-:--:--\u001b[0mSome input metadata could not be copied because it is not permitted in PDF/A. You may wish to examine the output PDF's XMP metadata.\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hImage optimization ratio: 1.22 savings: 18.2%\n",
      "Total file size ratio: 0.99 savings: -1.5%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "Start processing 8 pages concurrently\n",
      "    1 redoing OCR\n",
      "    2 redoing OCR\n",
      "    3 redoing OCR\n",
      "    4 redoing OCR\n",
      "    5 redoing OCR\n",
      "    6 redoing OCR\n",
      "    7 redoing OCR\n",
      "    8 redoing OCR\n",
      "    9 redoing OCR\n",
      "   10 redoing OCR\n",
      "   11 redoing OCR\n",
      "    6 [tesseract] lots of diacritics - possibly poor OCR\n",
      "Postprocessing...\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25hImage optimization ratio: 1.01 savings: 0.6%\n",
      "Total file size ratio: 0.99 savings: -0.6%\n",
      "Output file is a PDF/A-2B (as expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2001_andion.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e59270bbe45ed8de72188f37165c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2001_andion.pdf:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start processing 8 pages concurrently\n",
      "    1 page already has text! - rasterizing text and running OCR anyway\n",
      "    2 page already has text! - rasterizing text and running OCR anyway\n",
      "    3 page already has text! - rasterizing text and running OCR anyway\n",
      "    4 page already has text! - rasterizing text and running OCR anyway\n",
      "    5 page already has text! - rasterizing text and running OCR anyway\n",
      "    6 page already has text! - rasterizing text and running OCR anyway\n",
      "    7 page already has text! - rasterizing text and running OCR anyway\n",
      "    8 page already has text! - rasterizing text and running OCR anyway\n",
      "Postprocessing...\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25hImage optimization ratio: 1.23 savings: 19.0%\n",
      "Total file size ratio: 0.35 savings: -188.7%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "The output file size is 2.89× larger than the input file.\n",
      "Possible reasons for this include:\n",
      "--force-ocr was issued, causing transcoding.\n",
      "PDF/A conversion was enabled. (Try `--output-type pdf`.)\n",
      "\n",
      "Start processing 8 pages concurrently\n",
      "    6 [tesseract] lots of diacritics - possibly poor OCR\n",
      "Postprocessing...\n",
      "\u001b[?25lLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[32m  0/100\u001b[0m \u001b[36m-:--:--\u001b[0mSome input metadata could not be copied because it is not permitted in PDF/A. You may wish to examine the output PDF's XMP metadata.\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hImage optimization ratio: 1.23 savings: 18.8%\n",
      "Total file size ratio: 0.99 savings: -1.4%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "Start processing 8 pages concurrently\n",
      "    1 redoing OCR\n",
      "    2 redoing OCR\n",
      "    3 redoing OCR\n",
      "    4 redoing OCR\n",
      "    5 redoing OCR\n",
      "    6 redoing OCR\n",
      "    7 redoing OCR\n",
      "    8 redoing OCR\n",
      "    7 [tesseract] lots of diacritics - possibly poor OCR\n",
      "Postprocessing...\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25hImage optimization ratio: 1.01 savings: 1.2%\n",
      "Total file size ratio: 1.01 savings: 1.4%\n",
      "Output file is a PDF/A-2B (as expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2003_cadiergues.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea30e04f2d3458ca057d5f52dd1117e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2003_cadiergues.pdf:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EncryptedPdfError: Input PDF is encrypted. The encryption must be removed to\n",
      "perform OCR.\n",
      "\n",
      "For information about this PDF's security use\n",
      "    qpdf --show-encryption infilename\n",
      "\n",
      "You can remove the encryption using\n",
      "    qpdf --decrypt [--password=[password]] infilename\n",
      "\n",
      "InputFileError: File not found - ../data/ESMAT/2003_cadiergues.pdf_stripped.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2003_thiel.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EncryptedPdfError: Input PDF is encrypted. The encryption must be removed to\n",
      "perform OCR.\n",
      "\n",
      "For information about this PDF's security use\n",
      "    qpdf --show-encryption infilename\n",
      "\n",
      "You can remove the encryption using\n",
      "    qpdf --decrypt [--password=[password]] infilename\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3681b07ed1c45d09fdd88a9346d3bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2003_thiel.pdf:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EncryptedPdfError: Input PDF is encrypted. The encryption must be removed to\n",
      "perform OCR.\n",
      "\n",
      "For information about this PDF's security use\n",
      "    qpdf --show-encryption infilename\n",
      "\n",
      "You can remove the encryption using\n",
      "    qpdf --decrypt [--password=[password]] infilename\n",
      "\n",
      "InputFileError: File not found - ../data/ESMAT/2003_thiel.pdf_stripped.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2001_gradt.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EncryptedPdfError: Input PDF is encrypted. The encryption must be removed to\n",
      "perform OCR.\n",
      "\n",
      "For information about this PDF's security use\n",
      "    qpdf --show-encryption infilename\n",
      "\n",
      "You can remove the encryption using\n",
      "    qpdf --decrypt [--password=[password]] infilename\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5544cd700f844c7082df2f4bb840c513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 2001_gradt.pdf:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start processing 4 pages concurrently\n",
      "    1 page already has text! - rasterizing text and running OCR anyway\n",
      "    2 page already has text! - rasterizing text and running OCR anyway\n",
      "    3 page already has text! - rasterizing text and running OCR anyway\n",
      "    4 page already has text! - rasterizing text and running OCR anyway\n",
      "Postprocessing...\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25hImage optimization ratio: 1.11 savings: 9.9%\n",
      "Total file size ratio: 0.29 savings: -245.5%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "The output file size is 3.46× larger than the input file.\n",
      "Possible reasons for this include:\n",
      "--force-ocr was issued, causing transcoding.\n",
      "PDF/A conversion was enabled. (Try `--output-type pdf`.)\n",
      "\n",
      "Start processing 4 pages concurrently\n",
      "Postprocessing...\n",
      "\u001b[?25lLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[32m  0/100\u001b[0m \u001b[36m-:--:--\u001b[0mSome input metadata could not be copied because it is not permitted in PDF/A. You may wish to examine the output PDF's XMP metadata.\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hImage optimization ratio: 1.10 savings: 9.1%\n",
      "Total file size ratio: 0.93 savings: -7.0%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "Start processing 4 pages concurrently\n",
      "    1 redoing OCR\n",
      "    2 redoing OCR\n",
      "    3 redoing OCR\n",
      "    4 redoing OCR\n",
      "    2 [tesseract] lots of diacritics - possibly poor OCR\n",
      "Postprocessing...\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25hImage optimization ratio: 1.00 savings: 0.0%\n",
      "Total file size ratio: 0.95 savings: -5.7%\n",
      "Output file is a PDF/A-2B (as expected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1999_blais.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a186b2f69843dfb3ee9e37d360414d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 1999_blais.pdf:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start processing 8 pages concurrently\n",
      "    1 page already has text! - rasterizing text and running OCR anyway\n",
      "    2 page already has text! - rasterizing text and running OCR anyway\n",
      "    3 page already has text! - rasterizing text and running OCR anyway\n",
      "    4 page already has text! - rasterizing text and running OCR anyway\n",
      "    5 page already has text! - rasterizing text and running OCR anyway\n",
      "    6 page already has text! - rasterizing text and running OCR anyway\n",
      "    7 page already has text! - rasterizing text and running OCR anyway\n",
      "    8 page already has text! - rasterizing text and running OCR anyway\n",
      "Postprocessing...\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m0m\n",
      "\u001b[?25hImage optimization ratio: 1.10 savings: 9.3%\n",
      "Total file size ratio: 0.05 savings: -2064.9%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "The output file size is 21.65× larger than the input file.\n",
      "Possible reasons for this include:\n",
      "--force-ocr was issued, causing transcoding.\n",
      "PDF/A conversion was enabled. (Try `--output-type pdf`.)\n",
      "\n",
      "Start processing 8 pages concurrently\n",
      "Postprocessing...\n",
      "\u001b[?25lLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m  0%\u001b[0m \u001b[32m  0/100\u001b[0m \u001b[36m-:--:--\u001b[0mSome input metadata could not be copied because it is not permitted in PDF/A. You may wish to examine the output PDF's XMP metadata.\n",
      "\u001b[2KLinearizing           \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m100/100\u001b[0m \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hImage optimization ratio: 1.10 savings: 9.1%\n",
      "Total file size ratio: 0.97 savings: -2.6%\n",
      "Output file is a PDF/A-2B (as expected)\n",
      "Start processing 8 pages concurrently\n",
      "    1 redoing OCR\n",
      "    2 some text on this page cannot be mapped to characters: consider using --force-ocr instead\n",
      "    3 redoing OCR\n",
      "    4 some text on this page cannot be mapped to characters: consider using --force-ocr instead\n",
      "    5 redoing OCR\n",
      "    6 redoing OCR\n",
      "    7 redoing OCR\n",
      "    8 redoing OCR\n",
      "    6 [tesseract] Empty page!!\n",
      "    6 [tesseract] Empty page!!\n",
      "Postprocessing...\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents,desc='Document Processing'):\n",
    "    print(f\"Processing {doc}\")\n",
    "    try:\n",
    "        for i in tqdm(range(3), desc=f\"Processing {doc}\", leave=False):\n",
    "            if i == 0:\n",
    "                os.system(f'ocrmypdf --tesseract-timeout 0 --continue-on-soft-render-error --force-ocr {directory}/{doc} {directory}/{doc}_stripped.pdf')   # Stripped pdf\n",
    "            elif i == 1:    \n",
    "                os.system(f'ocrmypdf --sidecar {directory}/{doc}_strip_reocr.txt --continue-on-soft-render-error {directory}/{doc}_stripped.pdf {directory}/{doc}_strip_reocr.pdf') # Apply OCR, output file\n",
    "            elif i == 2:\n",
    "                os.system(f'ocrmypdf --sidecar {directory}/{doc}_reocr.txt --continue-on-soft-render-error --redo-ocr {directory}/{doc} {directory}/{doc}_reocr.pdf') # Apply OCR, output file\n",
    "    except:\n",
    "        print(f'Error processing {doc}')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

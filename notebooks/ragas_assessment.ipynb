{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas evaluation\n",
    "Test batch and ragas capability.\n",
    "\n",
    "Uses this article as a model: https://towardsdatascience.com/visualize-your-rag-data-evaluate-your-retrieval-augmented-generation-system-with-ragas-fc2486308557\n",
    "\n",
    "Ragas repository: https://github.com/explodinggradients/ragas/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas import RunConfig\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "import chromadb\n",
    "from chromadb import PersistentClient\n",
    "from pinecone import Pinecone as pinecone_client, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_voyageai import VoyageAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_correctness\n",
    "from datasets import Dataset\n",
    "\n",
    "from renumics import spotlight\n",
    "from renumics.spotlight import Embedding\n",
    "import pandas as pd\n",
    "\n",
    "from umap import UMAP\n",
    "import numpy as np\n",
    "\n",
    "# Import local packages\n",
    "sys.path.append('../src/aerospace_chatbot')\n",
    "import queries\n",
    "from data_processing import _stable_hash_meta, archive_db, get_docs_questions_df\n",
    "\n",
    "# Set environment variables with .env\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dict_to_file(data_dict, filename):\n",
    "    \"\"\"write a dictionary as a json line to a file - allowing for appending\"\"\"\n",
    "    with open(filename, \"a\") as f:\n",
    "        f.write(json.dumps(data_dict) + \"\\n\")\n",
    "\n",
    "def read_dicts_from_file(filename):\n",
    "    \"\"\"Read a json line file as a generator of dictionaries - allowing to load multiple dictionaries as list.\"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "            \n",
    "def add_cached_column_from_file(df, file_name, merge_on, column):\n",
    "    \"\"\"Read a file with cached list of dicts data write it to a dataframe.\"\"\"\n",
    "    if Path(file_name).exists():\n",
    "        cached_answer_correctness = (\n",
    "            pd.DataFrame(list(read_dicts_from_file(file_name)))\n",
    "            .drop_duplicates(\n",
    "                subset=[merge_on],\n",
    "            )[[column, merge_on]]\n",
    "            .dropna()\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        return df.merge(\n",
    "            cached_answer_correctness,\n",
    "            on=merge_on,\n",
    "            how=\"left\",\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        # Create a copy of the DataFrame\n",
    "        df_out = df.copy()\n",
    "\n",
    "        # Add the new column with the name of the variable 'column'\n",
    "        df_out[column] = None\n",
    "\n",
    "        # Reorder the columns to place the new column at the end\n",
    "        columns = list(df_out.columns)\n",
    "        columns.remove(column)\n",
    "        columns.append(column)\n",
    "        df_out = df_out[columns]\n",
    "        \n",
    "        return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_responses(index_type, index_name, query_model, llm, QA_model_params, df_questions_answers_in, df_docs):\n",
    "    df_questions_answers_out=df_questions_answers_in.copy()\n",
    "    \n",
    "    # Generate responses using RAG with input parameters\n",
    "    for i, row in df_questions_answers_out.iterrows():\n",
    "        if row['answer'] is None or pd.isnull(row['answer']) or row['answer']=='':\n",
    "            print(f\"Processing question {i+1}/{len(df_questions_answers_out)}\")\n",
    "\n",
    "            # Use the QA model to query the documents\n",
    "            qa_obj=queries.QA_Model(index_type,\n",
    "                            index_name,\n",
    "                            query_model,\n",
    "                            llm,\n",
    "                            **QA_model_params)\n",
    "            qa_obj.query_docs(row['question'])\n",
    "            response=qa_obj.result\n",
    "\n",
    "            df_questions_answers_out.loc[df_questions_answers_out.index[i], \"answer\"] = response['answer'].content\n",
    "\n",
    "            ids=[_stable_hash_meta(source_document.metadata)\n",
    "                for source_document in response['references']]\n",
    "            df_questions_answers_out.loc[df_questions_answers_out.index[i], \"source_documents\"] = ', '.join(ids)\n",
    "\n",
    "            # Save the response to cache file\n",
    "            response_dict = {\n",
    "                \"question\": row['question'],\n",
    "                \"answer\": response['answer'].content,\n",
    "                \"source_documents\": ids,\n",
    "            }\n",
    "            write_dict_to_file(response_dict, f'rag_response_cache_{index_name}.json')\n",
    "\n",
    "    # Get the context documents content for each question\n",
    "    source_documents_list = []\n",
    "    for cell in df_questions_answers_out['source_documents']:\n",
    "        cell_list = cell.strip('[]').split(', ')\n",
    "        context=[]\n",
    "        for cell in cell_list:\n",
    "            context.append(df_docs[df_docs[\"id\"] == cell][\"document\"].values[0])\n",
    "        source_documents_list.append(context)\n",
    "    df_questions_answers_out[\"contexts\"]=source_documents_list\n",
    "\n",
    "    # Addtionaly get embeddings for questions\n",
    "    if not Path(f'question_embeddings_{index_name}.pickle').exists():\n",
    "        question_embeddings = [\n",
    "            query_model.embed_query(question)\n",
    "            for question in df_questions_answers_out[\"question\"]\n",
    "        ]\n",
    "        with open(f'question_embeddings_{index_name}.pickle', \"wb\") as f:\n",
    "            pickle.dump(question_embeddings, f)\n",
    "\n",
    "    question_embeddings = pickle.load(open(f'question_embeddings_{index_name}.pickle', \"rb\"))\n",
    "    df_questions_answers_out[\"embedding\"] = question_embeddings\n",
    "    return df_questions_answers_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rag(index_name, df_questions_answers_in):\n",
    "    df_questions_answers_out=df_questions_answers_in.copy()\n",
    "\n",
    "    # Add answer correctness column, fill in if it exists\n",
    "    df_questions_answers_out = add_cached_column_from_file(\n",
    "        df_questions_answers_out, f'ragas_result_cache_{index_name}.json', \"question\", \"answer_correctness\"\n",
    "    )\n",
    "\n",
    "    # Unclear why but sometimes ground_truth does not provide a response. Just filter those out.\n",
    "    df_questions_answers_out = df_questions_answers_out[df_questions_answers_out['ground_truth'].apply(lambda x: isinstance(x, str))]\n",
    "    df_questions_answers_out\n",
    "\n",
    "    # Prepare the dataframe for evaluation\n",
    "    df_qa_eval = df_questions_answers_out.copy()\n",
    "\n",
    "    # Evaluate the answer correctness if not already done\n",
    "    fields = [\"question\", \"answer\", \"contexts\", \"ground_truth\"]\n",
    "    for i, row in df_qa_eval.iterrows():\n",
    "        print(i, row[\"question\"])\n",
    "        if row[\"answer_correctness\"] is None or pd.isnull(row[\"answer_correctness\"]):\n",
    "            evaluation_result = evaluate(\n",
    "                Dataset.from_pandas(df_qa_eval.iloc[i : i + 1][fields]),\n",
    "                [answer_correctness],\n",
    "            )\n",
    "            df_qa_eval.loc[i, \"answer_correctness\"] = evaluation_result[\n",
    "                \"answer_correctness\"\n",
    "            ]\n",
    "\n",
    "            # optionally save the response to cache\n",
    "            response_dict = {\n",
    "                \"question\": row[\"question\"],\n",
    "                \"answer_correctness\": evaluation_result[\"answer_correctness\"],\n",
    "            }\n",
    "            write_dict_to_file(response_dict, f'ragas_result_cache_{index_name}.json')\n",
    "\n",
    "    # write the answer correctness to the original dataframe\n",
    "    df_questions_answers_out[\"answer_correctness\"] = df_qa_eval[\"answer_correctness\"]\n",
    "\n",
    "    return df_qa_eval, df_questions_answers_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_viz_prep(index_name,df_qa_eval,df_docs):\n",
    "    # This section adds a column to df_documents containing the ids of the questions that used the document as source. \n",
    "\n",
    "    # add the infos about questions using each document to the documents dataframe\n",
    "\n",
    "    # Explode 'source_documents' so each document ID is in its own row alongside the question ID\n",
    "    df_questions_exploded = df_qa_eval.explode(\"source_documents\")\n",
    "\n",
    "    # Group by exploded 'source_documents' (document IDs) and aggregate\n",
    "    agg = (\n",
    "        df_questions_exploded.groupby(\"source_documents\")\n",
    "        .agg(\n",
    "            num_questions=(\"id\", \"count\"),  # Count of questions referencing the document\n",
    "            question_ids=(\n",
    "                \"id\",\n",
    "                lambda x: list(x),\n",
    "            ),  # List of question IDs referencing the document\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={\"source_documents\": \"id\"})\n",
    "    )\n",
    "\n",
    "    # Merge the aggregated information back into df_documents\n",
    "    df_documents_agg = pd.merge(df_docs, agg, on=\"id\", how=\"left\")\n",
    "\n",
    "    # Use apply to replace NaN values with empty lists for 'question_ids'\n",
    "    df_documents_agg[\"question_ids\"] = df_documents_agg[\"question_ids\"].apply(\n",
    "        lambda x: x if isinstance(x, list) else []\n",
    "    )\n",
    "    # Replace NaN values in 'num_questions' with 0\n",
    "    df_documents_agg[\"num_questions\"] = df_documents_agg[\"num_questions\"].fillna(0)\n",
    "\n",
    "    # Concatenate the two dataframes\n",
    "    df_visualize = pd.concat([df_qa_eval, df_documents_agg], axis=0)\n",
    "\n",
    "    df_questions = df_visualize[~df_visualize[\"question\"].isna()]\n",
    "    umap = UMAP(n_neighbors=20, min_dist=0.15, metric=\"cosine\", random_state=42).fit(\n",
    "        df_questions[\"embedding\"].values.tolist()\n",
    "    )\n",
    "    umap_questions = umap.transform(df_visualize[\"embedding\"].values.tolist())\n",
    "\n",
    "\n",
    "    df_without_questions = df_visualize[df_visualize[\"question\"].isna()]\n",
    "    umap = UMAP(n_neighbors=20, min_dist=0.15, metric=\"cosine\", random_state=42).fit(\n",
    "        df_without_questions[\"embedding\"].values.tolist()\n",
    "    )\n",
    "    umap_docs = umap.transform(df_visualize[\"embedding\"].values.tolist())\n",
    "    df_visualize[\"umap_docs\"] = umap_docs.tolist()\n",
    "\n",
    "    umap = UMAP(n_neighbors=20, min_dist=0.15, metric=\"cosine\", random_state=42).fit(\n",
    "        df_visualize[\"embedding\"].values.tolist()\n",
    "    )\n",
    "    umap_all = umap.transform(df_visualize[\"embedding\"].values.tolist())\n",
    "    df_visualize[\"umap\"] = umap_all.tolist()\n",
    "\n",
    "\n",
    "    # find the nearet question (by embedding) for each document\n",
    "    question_embeddings = np.array(df_visualize[df_visualize[\"question\"].notna()][\"embedding\"].tolist())\n",
    "\n",
    "    df_visualize[\"nearest_question_dist\"] = [  # brute force, could be optimized using ChromaDB\n",
    "        np.min([np.linalg.norm(np.array(doc_emb) - question_embeddings, axis=1)])\n",
    "        for doc_emb in df_visualize[\"embedding\"].values\n",
    "    ]\n",
    "\n",
    "    # write the dataframe to parquet for later use\n",
    "    df_visualize.to_parquet(f'df_{index_name}.parquet')\n",
    "\n",
    "    return df_visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=text-embedding-3-large-2merge-0),\n",
       " Collection(name=text-embedding-3-large-0merge-400),\n",
       " Collection(name=text-embedding-3-large-0merge-400-parent-child),\n",
       " Collection(name=text-embedding-3-large-2merge-0-queries)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_client = chromadb.PersistentClient(path=os.path.join(os.getenv('LOCAL_DB_PATH'),'chromadb'))   \n",
    "collections=persistent_client.list_collections()\n",
    "collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs=[{'index_name':'text-embedding-3-large-2merge-0',\n",
    "     'query_model':OpenAIEmbeddings(model='text-embedding-3-large',openai_api_key=os.getenv('OPENAI_API_KEY'))},\n",
    "     {'index_name':'text-embedding-3-large-0merge-400',\n",
    "     'query_model':OpenAIEmbeddings(model='text-embedding-3-large',openai_api_key=os.getenv('OPENAI_API_KEY'))},\n",
    "     {'index_name':'text-embedding-3-large-0merge-400-parent-child',\n",
    "     'query_model':OpenAIEmbeddings(model='text-embedding-3-large',openai_api_key=os.getenv('OPENAI_API_KEY'))},\n",
    "     {'index_name':'text-embedding-3-large-2merge-0-queries',\n",
    "     'query_model':OpenAIEmbeddings(model='text-embedding-3-large',openai_api_key=os.getenv('OPENAI_API_KEY'))}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first db, save for synthetic test dataset\n",
    "db=dbs[0]\n",
    "docs_vectorstore = Chroma(client=persistent_client,\n",
    "                        collection_name=db['index_name'],\n",
    "                        embedding_function=db['query_model'])  \n",
    "all_docs = docs_vectorstore.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "lcdocs_chroma = [Document(page_content=doc, metadata=metadata) \n",
    "          for doc, metadata in zip(all_docs['documents'], all_docs['metadatas'])]\n",
    "\n",
    "print(len(lcdocs_chroma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all collections to pickles to store them\n",
    "for db in dbs:\n",
    "    df_temp_chroma=archive_db('ChromaDB',db['index_name'],db['query_model'],export_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>page</th>\n",
       "      <th>metadata</th>\n",
       "      <th>document</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001889abd34c56d712ba79f905d7b90159f5c354</td>\n",
       "      <td>['AMS_2001_reocr.pdf', 'AMS_2001_reocr.pdf']</td>\n",
       "      <td>[37, 38]</td>\n",
       "      <td>{'page': '[37, 38]', 'source': '['AMS_2001_reo...</td>\n",
       "      <td>Using a Ball Aerospace-developed  lubricant  f...</td>\n",
       "      <td>[0.013638148084282875, -0.023859944194555283, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001bc8af131361ed46a8999ade3e7068522572a1</td>\n",
       "      <td>['AMS_2016_reocr.pdf', 'AMS_2016_reocr.pdf']</td>\n",
       "      <td>[172, 173]</td>\n",
       "      <td>{'page': '[172, 173]', 'source': '['AMS_2016_r...</td>\n",
       "      <td>158 Design Ideology and Testing  \\n\\nEarly Des...</td>\n",
       "      <td>[0.0009454930550418794, 0.018359793350100517, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030b47c6180d167c2d013c8e7a8b8bb0c16de44</td>\n",
       "      <td>['AMS_2001_reocr.pdf', 'AMS_2001_reocr.pdf']</td>\n",
       "      <td>[43, 44]</td>\n",
       "      <td>{'page': '[43, 44]', 'source': '['AMS_2001_reo...</td>\n",
       "      <td>The Vertrel XF treated bearing had a slight am...</td>\n",
       "      <td>[-0.00619348743930459, -0.028075991198420525, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00356e19ac534a10e86a774fa22603978622d654</td>\n",
       "      <td>['AMS_2018_reocr.pdf', 'AMS_2018_reocr.pdf']</td>\n",
       "      <td>[523, 524]</td>\n",
       "      <td>{'page': '[523, 524]', 'source': '['AMS_2018_r...</td>\n",
       "      <td>•Terminate the test at the first onset of unex...</td>\n",
       "      <td>[-0.036841981112957, -0.022101974114775658, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003edd3f9efa244ccfd87445ebd5edff5c3155b3</td>\n",
       "      <td>['AMS_2020_reocr.pdf', 'AMS_2020_reocr.pdf']</td>\n",
       "      <td>[197, 198]</td>\n",
       "      <td>{'page': '[197, 198]', 'source': '['AMS_2020_r...</td>\n",
       "      <td>7 oe ~ Of Dual ~187 a highly loaded planet, a ...</td>\n",
       "      <td>[-0.002627367153763771, -0.006074088159948587,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  001889abd34c56d712ba79f905d7b90159f5c354   \n",
       "1  001bc8af131361ed46a8999ade3e7068522572a1   \n",
       "2  0030b47c6180d167c2d013c8e7a8b8bb0c16de44   \n",
       "3  00356e19ac534a10e86a774fa22603978622d654   \n",
       "4  003edd3f9efa244ccfd87445ebd5edff5c3155b3   \n",
       "\n",
       "                                         source        page  \\\n",
       "0  ['AMS_2001_reocr.pdf', 'AMS_2001_reocr.pdf']    [37, 38]   \n",
       "1  ['AMS_2016_reocr.pdf', 'AMS_2016_reocr.pdf']  [172, 173]   \n",
       "2  ['AMS_2001_reocr.pdf', 'AMS_2001_reocr.pdf']    [43, 44]   \n",
       "3  ['AMS_2018_reocr.pdf', 'AMS_2018_reocr.pdf']  [523, 524]   \n",
       "4  ['AMS_2020_reocr.pdf', 'AMS_2020_reocr.pdf']  [197, 198]   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'page': '[37, 38]', 'source': '['AMS_2001_reo...   \n",
       "1  {'page': '[172, 173]', 'source': '['AMS_2016_r...   \n",
       "2  {'page': '[43, 44]', 'source': '['AMS_2001_reo...   \n",
       "3  {'page': '[523, 524]', 'source': '['AMS_2018_r...   \n",
       "4  {'page': '[197, 198]', 'source': '['AMS_2020_r...   \n",
       "\n",
       "                                            document  \\\n",
       "0  Using a Ball Aerospace-developed  lubricant  f...   \n",
       "1  158 Design Ideology and Testing  \\n\\nEarly Des...   \n",
       "2  The Vertrel XF treated bearing had a slight am...   \n",
       "3  •Terminate the test at the first onset of unex...   \n",
       "4  7 oe ~ Of Dual ~187 a highly loaded planet, a ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.013638148084282875, -0.023859944194555283, ...  \n",
       "1  [0.0009454930550418794, 0.018359793350100517, ...  \n",
       "2  [-0.00619348743930459, -0.028075991198420525, ...  \n",
       "3  [-0.036841981112957, -0.022101974114775658, -0...  \n",
       "4  [-0.002627367153763771, -0.006074088159948587,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp_chroma.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good article on how models/embeddings are used in the `TestsetGenerator`: https://www.pondhouse-data.com/blog/evaluate-rag-performance-using-ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set generator inputs\n",
    "generator_model=\"gpt-3.5-turbo-16k\"\n",
    "synthetic_generator_llm = ChatOpenAI(model=generator_model, tags=[generator_model])\n",
    "\n",
    "critic_model='gpt-4o'\n",
    "synthetic_critic_llm = ChatOpenAI(model=critic_model,tags=[critic_model])\n",
    "\n",
    "embedding_model='text-embedding-3-large'\n",
    "synthetic_embeddings = OpenAIEmbeddings(model=embedding_model,api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022502250225022502\n"
     ]
    }
   ],
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    synthetic_generator_llm,\n",
    "    synthetic_critic_llm,\n",
    "    synthetic_embeddings\n",
    ")\n",
    "\n",
    "sample_size=50\n",
    "percent_total=sample_size/len(lcdocs_chroma)\n",
    "print(percent_total)\n",
    "\n",
    "# Get a random sample of lcdocs\n",
    "lcdocs_random = random.sample(lcdocs_chroma, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06069b3143e4fbdb035ccdf3bd2a952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad382b8b7a8347a08c3b21d71f328ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['REACT mechanism', 'Qualification testing', 'Deployable solar panel', 'Actuator', 'Thermal vacuum testing']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How was the REACT mechanism tested for integration within an SSTL HDRM for a small satellite deployable solar panel?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the testing of the REACT mechanism for integration within an SSTL HDRM for a small satellite deployable solar panel. It specifies the mechanism (REACT), the context (SSTL HDRM), and the application (small satellite deployable solar panel), making the intent clear. However, it assumes familiarity with specific terms (REACT mechanism, SSTL HDRM) without providing definitions or context. To improve clarity and answerability, the question could include brief explanations of these terms or specify the aspects of testing (e.g., methods, results, challenges) it is interested in.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: How was the REACT mechanism tested for integration within an SSTL HDRM for a small satellite deployable solar panel?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the steps involved in testing the integration of the REACT mechanism within an SSTL HDRM for a small satellite deployable solar panel. It is specific in terms of the components involved (REACT mechanism, SSTL HDRM, small satellite deployable solar panel) and the process (testing the integration). The intent is clear, seeking a detailed description of the testing steps. The question is self-contained and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: What were the steps involved in testing the integration of the REACT mechanism within an SSTL HDRM for a small satellite deployable solar panel?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the testing steps of the REACT mechanism integration within an SSTL HDRM for a small satellite deployable solar panel, sharing the same constraints, requirements, depth, and breadth of inquiry.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['University of Chicago', 'far-infrared polarimeter', 'Stratospheric Observatory for Infrared Astronomy', 'rotating carousel-style stage', 'polarizing half-wave plates', 'cryogenic motor', 'HWP module', 'liquid helium', 'rotational position', 'motor heat', 'cryogenic motor', 'planetary gear unit', 'HWP Bearing', 'precision X-bearing', 'flight environment', 'microphonic effects', 'clear aperture']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the purpose of having a clear aperture in the design of the HWP module?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the purpose of having a clear aperture in the design of the HWP (Half-Wave Plate) module. It is specific and clear in its intent, seeking an explanation of the design choice. The question is self-contained and does not rely on external references or additional context to be understood and answered. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: What is the purpose of having a clear aperture in the design of the HWP module?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks why it is necessary for the HWP module to have a clear aperture in its design. It is specific and clear in its intent, seeking an explanation for a particular design choice in the HWP module. The question does not rely on external references or unspecified context, making it self-contained and understandable. Therefore, it meets the criteria for clarity and answerability.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: Why is it necessary for the HWP module to have a clear aperture in its design?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'Both questions inquire about the necessity of a clear aperture in the design of the HWP module, requiring the same depth and breadth of explanation.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] evolution_filter failed, retrying with 1\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 2 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Voltage', 'Oscilloscope trace', 'Noise sensitivity test', 'Resistance trace', 'Current level effects', 'Peak to peak noise', 'Role of environment', 'Pressure', 'Lead naphthenate', 'Peak-to-peak noise']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the relationship between peak to peak noise and surface speeds in the given context?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the relationship between peak to peak noise and surface speeds but refers to 'the given context' without providing or describing this context within the query. This makes the question unclear and dependent on external information that is not included. To improve clarity and answerability, the question should either include the relevant context directly within the question or be framed in a way that does not require external information. For example, specifying the type of surface, the conditions under which the measurements are taken, or the specific domain (e.g., automotive, aerospace) could help clarify the query.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: What is the relationship between peak to peak noise and surface speeds in the given context?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about the relationship between peak to peak noise and surface speeds but refers to 'the given context' without providing or describing this context within the query. This makes the question unclear and dependent on unspecified external information. To improve clarity and answerability, the question should either include the relevant context directly within the question or be framed in a way that does not require external information. For example, it could specify the type of surface, the conditions under which the measurements are taken, or any relevant parameters that define the context.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 3 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Separation nut heritage design', 'Pyroalliance achievements', 'Shock contributors assessment', 'Release piston impact', 'Damping system']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What were the main contributors to the induced shock in the separation nut heritage design?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the main contributors to the induced shock in the separation nut heritage design. It is clear in specifying the topic of interest (induced shock, separation nut heritage design) and seeks detailed information on the contributors. The question is self-contained and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: What were the main contributors to the induced shock in the separation nut heritage design?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the three main contributors to the induced shock in the separation nut heritage design according to Pyroalliance's assessment. It is specific in its request for three contributors and clearly identifies the source of the assessment (Pyroalliance). The question is self-contained and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided.\", 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: What were the three main contributors to the induced shock in the separation nut heritage design according to Pyroalliance's assessment?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': \"The first question asks about the main contributors to the induced shock in the separation nut heritage design in general, while the second question specifically asks for Pyroalliance's assessment on the same topic. This introduces a different constraint and requirement.\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': \"Pyroalliance's assessment identified three main contributors to the induced shock in the separation nut heritage design: pyrotechnic shock due to the initiator actuation, strain energy stored in the screw during the preload and released during the release, and kinetic energy stored in the release piston during the release and distributed during following shocks with other mechanical parts.\", 'verdict': '1'}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Planetary gear unit', 'Worm gear arrangement', 'Friction', 'Gear ratio', 'Step count', 'Rotational accuracy', 'Polarization studies', 'Magnetoresistive position sensor', 'Cryogenic sensors', 'Infineon Technologies', 'Semiconductor magnetoresistors', 'Plastic housing', 'Temperature resistance', 'Output signals', 'Electronic circuit', 'Digital counter', 'HWP location information', 'Prototype testing', 'Ferromagnetic chip', 'Rotating HWP holder', 'Stationary sensor', 'Future implementation']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What material was used for the housing of the sensor?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking for the material used for the housing of a sensor. It does not rely on external references or additional context, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] simple question generated: What material was used for the housing of the sensor?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question is clear and specific, asking for the type of material used for the housing of a sensor recommended by Infineon Technologies. It does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [ReasoningEvolution] question compressed: What type of material was used for the housing of the sensor that was recommended by Infineon Technologies?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The first question asks about the material used for the housing of a sensor in general, while the second question specifies the material recommended by Infineon Technologies for sensor housing. This difference in specificity leads to different constraints and requirements.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The sensor was contained in a plastic housing.', 'verdict': '1'}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Planetary gear unit', 'Worm gear arrangement', 'Friction', 'Gear ratio', 'Step count', 'Rotational accuracy', 'Polarization studies', 'Magnetoresistive position sensor', 'Cryogenic sensors', 'Infineon Technologies', 'Semiconductor magnetoresistors', 'Plastic housing', 'Temperature resistance', 'Output signals', 'Electronic circuit', 'Digital counter', 'HWP location information', 'Prototype testing', 'Ferromagnetic chip', 'Rotating HWP holder', 'Stationary sensor', 'Future implementation']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What type of cryogenic sensors were investigated for sensing the HWP position?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the type of cryogenic sensors investigated for sensing the HWP (Half-Wave Plate) position. It is clear in specifying the subject of interest (cryogenic sensors) and the context (sensing the HWP position). The intent is straightforward, seeking information on the specific types of sensors used. The question is self-contained and does not rely on external references or additional context to be understood and answered.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'small cryogenic sensors', 'verdict': '1'}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Planetary gear unit', 'Worm gear arrangement', 'Friction', 'Gear ratio', 'Step count', 'Rotational accuracy', 'Polarization studies', 'Magnetoresistive position sensor', 'Cryogenic sensors', 'Infineon Technologies', 'Semiconductor magnetoresistors', 'Plastic housing', 'Temperature resistance', 'Output signals', 'Electronic circuit', 'Digital counter', 'HWP location information', 'Prototype testing', 'Ferromagnetic chip', 'Rotating HWP holder', 'Stationary sensor', 'Future implementation']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the theoretical step count for a complete revolution in the given context?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the theoretical step count for a complete revolution but refers to an unspecified 'given context'. This makes the question unclear and dependent on external information that is not provided within the question itself. To improve clarity and answerability, the question should include the specific context or parameters that define the 'complete revolution' (e.g., the type of system, the mechanism involved, or any relevant mathematical or physical principles).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: What is the theoretical step count for a complete revolution in the given context?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks for the theoretical step count for a complete revolution but refers to an unspecified 'given context'. This makes the question unclear and dependent on external information that is not provided within the question itself. To improve clarity and answerability, the question should include the specific context or parameters that define the 'complete revolution' (e.g., the type of system, the mechanism involved, or any relevant mathematical or physical principles).\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 1, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.25}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['lubrication condition', 'bell jar', 'steel bearings', 'hybrid bearings', 'motor torque']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: How was motor torque recorded and monitored during the testing?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the methods used to record and monitor motor torque during testing. It is clear in its intent, specifying the focus on the recording and monitoring processes of motor torque. The question is independent and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] simple question generated: How was motor torque recorded and monitored during the testing?\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question generated: How was the torque of the motors recorded and monitored during the testing, and what was the significance of the torque measurements in relation to the bearing failures?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about the methods used to record and monitor the torque of motors during testing and the significance of these torque measurements in relation to bearing failures. It is clear in specifying the two main points of interest: the recording/monitoring process and the relevance of the measurements to bearing failures. The question is self-contained and does not rely on external references or unspecified contexts, making it understandable and answerable based on the details provided.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] [MultiContextEvolution] multicontext question compressed: How was the motor torque recorded and monitored during testing, and what was the significance of the measurements in relation to the bearing failures?\n",
      "[ragas.testset.filters.DEBUG] evolution filter: {'reason': 'The second question not only asks about the recording and monitoring of motor torque but also inquires about the significance of these measurements in relation to bearing failures, adding an additional layer of depth.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The motor torque was recorded at the beginning of the life test and monitored throughout the testing. Any observed increases in torque were attributed to bearing drag since the motor torque was constant over time. The significance of the measurements in relation to the bearing failures was that an increase in torque indicated bearing failure or depletion of the lubricant.', 'verdict': '1'}\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['High force linear actuator', 'Welded disk system', 'SLM process', 'Pilot Pressure', 'High pressure balance chamber', 'Gagable actuator', 'HP chamber', 'Internal pressure', 'Concepts Development', 'MSFC and GSFC', 'Preliminary analysis', 'Fracture plate', 'Linear Disk Valve', 'Manufacturing costs', 'Traditional solenoid system', 'Ball latch system', 'SLM manufacturing methods', 'Valve body', 'Actuator load requirements', 'Dual Disk design', 'Shear plunger', 'Internal hermetic seal']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What concepts were developed by MSFC and GSFC during the development process?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': \"The question asks about concepts developed by MSFC (Marshall Space Flight Center) and GSFC (Goddard Space Flight Center) during a development process. However, it lacks specificity regarding which development process is being referred to, as both centers have been involved in numerous projects and initiatives. To improve clarity and answerability, the question should specify the particular project, program, or time frame of interest. For example, 'What concepts were developed by MSFC and GSFC during the development of the Artemis program?'\", 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] rewritten question: What concepts were developed by MSFC and GSFC during the development process?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks about concepts developed by MSFC (Marshall Space Flight Center) and GSFC (Goddard Space Flight Center) during a development process. However, it lacks specificity regarding which development process is being referred to, making it ambiguous. To improve clarity and answerability, the question should specify the particular project or development process (e.g., a specific space mission, technology development, or research initiative) in which these concepts were developed.', 'verdict': 0}\n",
      "[ragas.testset.evolutions.INFO] retrying evolution: 1 times\n",
      "[ragas.testset.filters.DEBUG] context scoring: {'clarity': 2, 'depth': 3, 'structure': 2, 'relevance': 3, 'score': 2.5}\n",
      "[ragas.testset.evolutions.DEBUG] keyphrases in merged node: ['Separation nut heritage design', 'Pyroalliance achievements', 'Shock contributors assessment', 'Release piston impact', 'Damping system']\n",
      "[ragas.testset.evolutions.INFO] seed question generated: What is the purpose of the damping system in the M10 separation nut design?\n",
      "[ragas.testset.filters.DEBUG] filtered question: {'feedback': 'The question asks for the purpose of the damping system in the M10 separation nut design. It is specific, independent, and has a clear intent, making it understandable and answerable based on the details provided. The question does not rely on external references or additional context, and it clearly seeks information about the function of a particular component within a specified design.', 'verdict': 1}\n",
      "[ragas.testset.evolutions.DEBUG] answer generated: {'answer': 'The purpose of the damping system in the M10 separation nut design is to perform a progressive braking of the release piston without degrading the reliability of the global system.', 'verdict': '1'}\n"
     ]
    }
   ],
   "source": [
    "# Check if testset.csv exists, use, or generate the synthetic dataset.\n",
    "if not os.path.exists('./testset.csv'):\n",
    "    run_config=RunConfig(timeout=1000,\n",
    "                    max_retries=50,\n",
    "                    max_wait=1000,\n",
    "                    max_workers=1)\n",
    "\n",
    "    n_questions=5\n",
    "    testset = generator.generate_with_langchain_docs(lcdocs_random, \n",
    "                                                    test_size=n_questions,\n",
    "                                                    with_debugging_logs=True,\n",
    "                                                    is_async=False,\n",
    "                                                    run_config=run_config,\n",
    "                                                    raise_exceptions=False)\n",
    "    df_testset=testset.to_pandas()\n",
    "    df_testset.to_csv(f\"testset_{db['index_name']}.csv\", index=False)\n",
    "else:\n",
    "    # Import testset.csv into a DataFrame\n",
    "    df_testset = pd.read_csv(f\"testset_{db['index_name']}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What type of cryogenic sensors were investigat...</td>\n",
       "      <td>[ besides  the planetary  gear unit, to transf...</td>\n",
       "      <td>small cryogenic sensors</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'page': '[44, 45]', 'source': '['AMS_2002_re...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of the damping system in t...</td>\n",
       "      <td>[‘elease nd quantifment  — threaded~ was 207 P...</td>\n",
       "      <td>The purpose of the damping system in the M10 s...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'page': '[217, 218]', 'source': '['AMS_2020_...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What material was used for the recommended sen...</td>\n",
       "      <td>[ besides  the planetary  gear unit, to transf...</td>\n",
       "      <td>The sensor was contained in a plastic housing.</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'page': '[44, 45]', 'source': '['AMS_2002_re...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How was the motor torque recorded and monitore...</td>\n",
       "      <td>[~oL,  a a  ~~  ~~  )4/heptane) __ and  instal...</td>\n",
       "      <td>The motor torque was recorded at the beginning...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'page': '[289, 290]', 'source': '['AMS_2020_...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to Pyroalliance's assessment, what w...</td>\n",
       "      <td>[‘elease nd quantifment  — threaded~ was 207 P...</td>\n",
       "      <td>Pyroalliance's assessment identified three mai...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'page': '[217, 218]', 'source': '['AMS_2020_...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What type of cryogenic sensors were investigat...   \n",
       "1  What is the purpose of the damping system in t...   \n",
       "2  What material was used for the recommended sen...   \n",
       "3  How was the motor torque recorded and monitore...   \n",
       "4  According to Pyroalliance's assessment, what w...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [ besides  the planetary  gear unit, to transf...   \n",
       "1  [‘elease nd quantifment  — threaded~ was 207 P...   \n",
       "2  [ besides  the planetary  gear unit, to transf...   \n",
       "3  [~oL,  a a  ~~  ~~  )4/heptane) __ and  instal...   \n",
       "4  [‘elease nd quantifment  — threaded~ was 207 P...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0                            small cryogenic sensors         simple   \n",
       "1  The purpose of the damping system in the M10 s...         simple   \n",
       "2     The sensor was contained in a plastic housing.      reasoning   \n",
       "3  The motor torque was recorded at the beginning...  multi_context   \n",
       "4  Pyroalliance's assessment identified three mai...      reasoning   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'page': '[44, 45]', 'source': '['AMS_2002_re...          True  \n",
       "1  [{'page': '[217, 218]', 'source': '['AMS_2020_...          True  \n",
       "2  [{'page': '[44, 45]', 'source': '['AMS_2002_re...          True  \n",
       "3  [{'page': '[289, 290]', 'source': '['AMS_2020_...          True  \n",
       "4  [{'page': '[217, 218]', 'source': '['AMS_2020_...          True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG questions/answers (batch mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format dataset and database for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = df_testset[['question', 'ground_truth']].copy()\n",
    "df_questions['id'] = 'Question ' + df_questions.index.astype(str)\n",
    "df_questions['question_by'] = generator_model\n",
    "df_questions = df_questions[['id', 'question', 'ground_truth', 'question_by']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = docs_vectorstore.get(include=[\"metadatas\", \"documents\", \"embeddings\"])\n",
    "df_docs = pd.DataFrame(\n",
    "    {\n",
    "        \"id\": [_stable_hash_meta(metadata) for metadata in all_docs[\"metadatas\"]],\n",
    "        \"source\": [metadata.get(\"source\") for metadata in all_docs[\"metadatas\"]],\n",
    "        \"page\": [metadata.get(\"page\", -1) for metadata in all_docs[\"metadatas\"]],\n",
    "        \"document\": all_docs[\"documents\"],\n",
    "        \"embedding\": all_docs[\"embeddings\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cached RAG answers and source_documents ids from a file - or create an empty column\n",
    "df_questions_answers = add_cached_column_from_file(\n",
    "    df_questions, f\"rag_response_cache_{db['index_name']}.txt\", \"question\", \"answer\")\n",
    "\n",
    "df_questions_answers = add_cached_column_from_file(\n",
    "    df_questions_answers, f\"rag_response_cache_{db['index_name']}.txt\", \"question\", \"source_documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use RAG to generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_type='ChromaDB'\n",
    "index_name=db['index_name']\n",
    "query_model=synthetic_embeddings\n",
    "llm=synthetic_generator_llm\n",
    "\n",
    "QA_model_params={'rag_type':'Standard',\n",
    "                 'k':4,\n",
    "                 'search_type':'similarity',\n",
    "                 'local_db_path':os.getenv('LOCAL_DB_PATH')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing question 1/5\n",
      "Processing question 2/5\n",
      "Processing question 3/5\n",
      "Processing question 4/5\n",
      "Processing question 5/5\n"
     ]
    }
   ],
   "source": [
    "df_questions_answers_rag=rag_responses(index_type, index_name, query_model, llm, QA_model_params, df_questions_answers, df_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ragas eval, visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 What type of cryogenic sensors were investigated for sensing the HWP position?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24ce416eb014e9387a1f01cd3dd364c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 What is the purpose of the damping system in the M10 separation nut design?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2b5a1668304c378bb21e8c547bd2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 What material was used for the recommended sensor housing by Infineon Technologies?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2146c9b1bfc244ad9718f7a3157c0077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 How was the motor torque recorded and monitored during testing, and what was the significance of the measurements in relation to the bearing failures?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c58af6e915642bb94066683c8d5e155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 According to Pyroalliance's assessment, what were the main contributors to the induced shock in the separation nut heritage design?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b121662ede1047c6bedd8545093116bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate\n",
    "df_qa_eval, df_questions_answers_rag = eval_rag(index_name, df_questions_answers_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>question_by</th>\n",
       "      <th>answer</th>\n",
       "      <th>source_documents</th>\n",
       "      <th>contexts</th>\n",
       "      <th>embedding</th>\n",
       "      <th>answer_correctness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question 0</td>\n",
       "      <td>What type of cryogenic sensors were investigat...</td>\n",
       "      <td>small cryogenic sensors</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>The study investigated the use of magnetoresis...</td>\n",
       "      <td>cbfbb0b161515dc8c73e456782988bfb9a65820b, fc15...</td>\n",
       "      <td>[At The University  of Chicago, we are designi...</td>\n",
       "      <td>[-0.013885260326153179, -0.001953278271540212,...</td>\n",
       "      <td>0.197826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question 1</td>\n",
       "      <td>What is the purpose of the damping system in t...</td>\n",
       "      <td>The purpose of the damping system in the M10 s...</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>The damping system in the M10 separation nut d...</td>\n",
       "      <td>197a4182c91b653cd2e11c7c874b3259dbf786f9, 9298...</td>\n",
       "      <td>[‘elease nd quantifment  — threaded~ was 207 P...</td>\n",
       "      <td>[-0.010085261674414852, -0.008000294874285226,...</td>\n",
       "      <td>0.48548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question 2</td>\n",
       "      <td>What material was used for the recommended sen...</td>\n",
       "      <td>The sensor was contained in a plastic housing.</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>According to Infineon Technologies, the advant...</td>\n",
       "      <td>4b2f9047be728770f2feff30dfd09561264f6361, 29e1...</td>\n",
       "      <td>[TQ 471 cable length max. 2m ji =H 1s 134 __q ...</td>\n",
       "      <td>[-0.016372018581599247, -0.0005170286489279663...</td>\n",
       "      <td>0.367569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Question 3</td>\n",
       "      <td>How was the motor torque recorded and monitore...</td>\n",
       "      <td>The motor torque was recorded at the beginning...</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>The motor torque was recorded and monitored du...</td>\n",
       "      <td>ec2cc226698a7aef0c03a24ca0e10c008aa2acc3, 54a9...</td>\n",
       "      <td>[taken at various points of the process yielde...</td>\n",
       "      <td>[0.012493401472138323, -0.010065259356331084, ...</td>\n",
       "      <td>0.852295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question 4</td>\n",
       "      <td>According to Pyroalliance's assessment, what w...</td>\n",
       "      <td>Pyroalliance's assessment identified three mai...</td>\n",
       "      <td>gpt-3.5-turbo-16k</td>\n",
       "      <td>According to Pyroalliance's assessment of the ...</td>\n",
       "      <td>197a4182c91b653cd2e11c7c874b3259dbf786f9, dee5...</td>\n",
       "      <td>[‘elease nd quantifment  — threaded~ was 207 P...</td>\n",
       "      <td>[0.011690869174125432, 0.0008642443597386778, ...</td>\n",
       "      <td>0.650764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                           question  \\\n",
       "0  Question 0  What type of cryogenic sensors were investigat...   \n",
       "1  Question 1  What is the purpose of the damping system in t...   \n",
       "2  Question 2  What material was used for the recommended sen...   \n",
       "3  Question 3  How was the motor torque recorded and monitore...   \n",
       "4  Question 4  According to Pyroalliance's assessment, what w...   \n",
       "\n",
       "                                        ground_truth        question_by  \\\n",
       "0                            small cryogenic sensors  gpt-3.5-turbo-16k   \n",
       "1  The purpose of the damping system in the M10 s...  gpt-3.5-turbo-16k   \n",
       "2     The sensor was contained in a plastic housing.  gpt-3.5-turbo-16k   \n",
       "3  The motor torque was recorded at the beginning...  gpt-3.5-turbo-16k   \n",
       "4  Pyroalliance's assessment identified three mai...  gpt-3.5-turbo-16k   \n",
       "\n",
       "                                              answer  \\\n",
       "0  The study investigated the use of magnetoresis...   \n",
       "1  The damping system in the M10 separation nut d...   \n",
       "2  According to Infineon Technologies, the advant...   \n",
       "3  The motor torque was recorded and monitored du...   \n",
       "4  According to Pyroalliance's assessment of the ...   \n",
       "\n",
       "                                    source_documents  \\\n",
       "0  cbfbb0b161515dc8c73e456782988bfb9a65820b, fc15...   \n",
       "1  197a4182c91b653cd2e11c7c874b3259dbf786f9, 9298...   \n",
       "2  4b2f9047be728770f2feff30dfd09561264f6361, 29e1...   \n",
       "3  ec2cc226698a7aef0c03a24ca0e10c008aa2acc3, 54a9...   \n",
       "4  197a4182c91b653cd2e11c7c874b3259dbf786f9, dee5...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [At The University  of Chicago, we are designi...   \n",
       "1  [‘elease nd quantifment  — threaded~ was 207 P...   \n",
       "2  [TQ 471 cable length max. 2m ji =H 1s 134 __q ...   \n",
       "3  [taken at various points of the process yielde...   \n",
       "4  [‘elease nd quantifment  — threaded~ was 207 P...   \n",
       "\n",
       "                                           embedding answer_correctness  \n",
       "0  [-0.013885260326153179, -0.001953278271540212,...           0.197826  \n",
       "1  [-0.010085261674414852, -0.008000294874285226,...            0.48548  \n",
       "2  [-0.016372018581599247, -0.0005170286489279663...           0.367569  \n",
       "3  [0.012493401472138323, -0.010065259356331084, ...           0.852295  \n",
       "4  [0.011690869174125432, 0.0008642443597386778, ...           0.650764  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_questions_answers_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danmueller/Documents/GitHub/aerospace_chatbot/.venv/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/Users/danmueller/Documents/GitHub/aerospace_chatbot/.venv/lib/python3.11/site-packages/umap/umap_.py:2437: UserWarning: n_neighbors is larger than the dataset size; truncating to X.shape[0] - 1\n",
      "  warn(\n",
      "/Users/danmueller/Documents/GitHub/aerospace_chatbot/.venv/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n",
      "/Users/danmueller/Documents/GitHub/aerospace_chatbot/.venv/lib/python3.11/site-packages/umap/umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "# Link from documents to questions, that used the document as source. Add UMAP column for visualization purposes.\n",
    "df_visualize=data_viz_prep(index_name,df_qa_eval,df_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the df containing the questions and the df containing the documents\n",
    "df = pd.read_parquet(f'df_{index_name}.parquet')\n",
    "\n",
    "# show the dataframe with the question and answer in spotlight\n",
    "spotlight.show(\n",
    "    df,\n",
    "    layout=\"https://spotlightpublic.blob.core.windows.net/docs-data/rag_demo/layout_rag_3.json\",\n",
    "    dtype={x: Embedding for x in df.keys() if \"umap\" in x},\n",
    ")\n",
    "\n",
    "##  UMAP visualization froms cluster of the questions, workaround: UMAP only on documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 1024,\n",
       "              'host': 'voyage-large-2-instruct-2merge-0-dj30h8y.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'voyage-large-2-instruct-2merge-0',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}},\n",
       "             {'dimension': 1024,\n",
       "              'host': 'voyage-large-2-instruct-0merge-400-dj30h8y.svc.aped-4627-b74a.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'voyage-large-2-instruct-0merge-400',\n",
       "              'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_client = pinecone_client(api_key=os.getenv('PINECONE_API_KEY'))\n",
    "indexes=pinecone_client.list_indexes()\n",
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs=[{'index_name':'voyage-large-2-instruct-2merge-0',\n",
    "     'query_model': VoyageAIEmbeddings(model='voyage-large-2-instruct', \n",
    "                                       voyage_api_key=os.getenv('VOYAGE_API_KEY'), truncation=False)},\n",
    "     {'index_name':'voyage-large-2-instruct-0merge-400',\n",
    "     'query_model': VoyageAIEmbeddings(model='voyage-large-2-instruct', \n",
    "                                       voyage_api_key=os.getenv('VOYAGE_API_KEY'), truncation=False)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first db, save for synthetic test dataset\n",
    "db=dbs[0]\n",
    "index = pinecone_client.Index(db['index_name'])\n",
    "ids=[]\n",
    "for id in index.list():\n",
    "    ids.extend(id)\n",
    "\n",
    "docs=[]\n",
    "chunk_size=200  # Tune to whatever doesn't error out, 200 won't for serverless\n",
    "for i in range(0, len(ids), chunk_size):\n",
    "    print(f\"Fetching {i} to {i+chunk_size}\")\n",
    "    vector=index.fetch(ids[i:i+chunk_size])['vectors']\n",
    "    vector_data = []\n",
    "    for key, value in vector.items():\n",
    "        vector_data.append(value)\n",
    "    docs.extend(vector_data)\n",
    "\n",
    "lcdocs_pinecone = []\n",
    "for data in docs:\n",
    "    data=data['metadata']\n",
    "    lcdocs_pinecone.append(Document(page_content=data['page_content'],\n",
    "                           metadata={'page':data['page'],'source':data['source']}))\n",
    "    \n",
    "print(len(lcdocs_pinecone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all collections to pickles to store them\n",
    "for db in dbs:\n",
    "    df_temp_pinecone=archive_db('Pinecone',db['index_name'],db['query_model'],export_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

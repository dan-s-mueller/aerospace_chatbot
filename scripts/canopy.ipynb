{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document processing (a few ways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "import re\n",
    "import pinecone\n",
    "import glob\n",
    "import json, jsonlines\n",
    "import uuid\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from canopy.tokenizer import Tokenizer\n",
    "from canopy.knowledge_base import KnowledgeBase\n",
    "from canopy.models.data_models import Document\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check api keys\n",
    "# print(os.getenv('OPENAI_API_KEY'))\n",
    "# print(os.getenv('PINECONE_ENVIRONMENT'))\n",
    "# print(os.getenv('PINECONE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ../data/AMS\\AMS_2018.pdf\n",
      "Processed: ../data/AMS\\AMS_2020.pdf\n",
      "Processed: ../data/AMS\\AMS_2022.pdf\n"
     ]
    }
   ],
   "source": [
    "# data_folder='../data/FEA/'\n",
    "data_folder='../data/AMS/'\n",
    "docs = glob.glob(data_folder+'*.pdf')   # Only get the PDFs in the directory\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 20,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")\n",
    "\n",
    "# print(docs[-1])\n",
    "# loader=PyPDFLoader(docs[-1])\n",
    "# doc_pages=loader.load_and_split(text_splitter)\n",
    "\n",
    "pages=[]\n",
    "for doc in docs[-3:]:\n",
    "    loader=PyPDFLoader(doc)\n",
    "    doc_pages=loader.load_and_split(text_splitter)\n",
    "    pages.extend(doc_pages)\n",
    "    print('Processed: '+doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy text up\n",
    "pages_dict=[]\n",
    "docs_canopy=[]\n",
    "for page in pages:\n",
    "    page.metadata['source']=os.path.basename(page.metadata['source'])   # Strip path\n",
    "    page.metadata['page']=int(page.metadata['page'])+1   # Pages are 0 based, update\n",
    "    # Merge hyphenated words\n",
    "    page.page_content=re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", page.page_content)\n",
    "    # Fix newlines in the middle of sentences\n",
    "    page.page_content = re.sub(r\"(?<!\\n\\s)\\n(?!\\s\\n)\", \" \", page.page_content.strip())\n",
    "    # Remove multiple newlines\n",
    "    page.page_content = re.sub(r\"\\n\\s*\\n\", \"\\n\\n\", page.page_content)\n",
    "\n",
    "    # Format into canopy format\n",
    "    dict_temp=dict(page)\n",
    "    dict_temp_out={'id':page.metadata['source']+\"_\"+str(page.metadata['page'])+str(uuid.uuid4()),\n",
    "                   'text':dict_temp.pop('page_content'),\n",
    "                   'source':dict_temp['metadata']['source'],\n",
    "                   'metadata':dict_temp['metadata']}\n",
    "    dict_temp_out['metadata']['page']=str(dict_temp_out['metadata']['page'])\n",
    "    pages_dict.append(dict_temp_out)\n",
    "\n",
    "\n",
    "    doc_temp=Document(id=page.metadata['source']+\"_\"+str(page.metadata['page'])+str(uuid.uuid4()),\n",
    "                        text=page.page_content,\n",
    "                        source=page.metadata['source'],\n",
    "                        metadata={'page':str(page.metadata['page'])})\n",
    "    docs_canopy.append(doc_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='44th Aerospace Mechanisms SymposiumNASA/CP—2018-219887 May 2018Edward A. Boesiger, Compiler Lockheed Martin Space Systems Company, Sunnyvale, California National Aeronautics and Space Administration Glenn Research Center Cleveland, Ohio 44135Proceedings of a conference held at Hilton Cleveland Downtown Hosted by NASA Glenn Research Center and Lockheed Martin Space Systems CompanySponsored and organized by Mechanisms Education AssociationCleveland, OhioMay 16–18, 2018' metadata={'source': 'AMS_2018.pdf', 'page': '5'}\n"
     ]
    }
   ],
   "source": [
    "print(pages[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'AMS_2018.pdf_1bfb03e76-1d88-4ded-a9c1-0f891f878ba1', 'text': '44th Aerospace Mechanisms SymposiumNASA/CP—2018-219887 May 2018Edward A. Boesiger, Compiler Lockheed Martin Space Systems Company, Sunnyvale, California', 'source': 'AMS_2018.pdf', 'metadata': {'source': 'AMS_2018.pdf', 'page': '1'}}\n"
     ]
    }
   ],
   "source": [
    "print(pages_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='AMS_2018.pdf_6b85047d9-8331-4c41-a99f-d6c0122c807d' text='44th Aerospace Mechanisms SymposiumNASA/CP—2018-219887 May 2018Edward A. Boesiger, Compiler Lockheed Martin Space Systems Company, Sunnyvale, California' source='AMS_2018.pdf' metadata={'page': '6'}\n"
     ]
    }
   ],
   "source": [
    "print(docs_canopy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open(data_folder+'ams_data.jsonl', mode='w') as writer:\n",
    "    writer.write_all(pages_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upserting docs for canopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command line interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we can switch across to Canopy CLI (or other method) and run:\n",
    "\n",
    "```\n",
    "canopy\n",
    "canopy upsert ./ai_arxiv.jsonl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canopy library for upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenizer.initialize()\n",
    "\n",
    "index_name='canopy--ams'\n",
    "kb = KnowledgeBase(index_name=index_name)\n",
    "kb.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 445/445 [08:55<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for i in tqdm(range(0, len(pages_dict), batch_size)):\n",
    "    kb.upsert(docs_canopy[i: i+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we begin chatting by first starting the Canopy Server:\n",
    "\n",
    "```\n",
    "canopy start\n",
    "```\n",
    "\n",
    "Then begin chatting with:\n",
    "\n",
    "```\n",
    "canopy chat\n",
    "```\n",
    "\n",
    "_(we can also add the `--no-rag` flag to see how our RAG vs. non-RAG results compare!)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from canopy.context_engine import ContextEngine\n",
    "context_engine = ContextEngine(kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from canopy.chat_engine import ChatEngine\n",
    "chat_engine = ChatEngine(context_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from canopy.models.data_models import Messages, UserMessage, AssistantMessage\n",
    "\n",
    "def chat(new_message: str, history: Messages) -> Tuple[str, Messages]:\n",
    "    messages = history + [UserMessage(content=new_message)]\n",
    "    response = chat_engine.chat(messages)\n",
    "    assistant_response = response.choices[0].message.content\n",
    "    return assistant_response, messages + [AssistantMessage(content=assistant_response)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The types of lubricants to be avoided when designing space mechanisms include Perf luoropolyethers (PFPE) and multiply alkylated cyclopentanes (MAC). These lubricants have issues with their tribofilm forming properties, which can lead to seizure and limited resupply of lubricant in vacuum conditions. It is also important to note that wet and binder-based lubricants are not suitable for space mechanisms due to their high outgassing properties. \n",
       "\n",
       "Source: AMS_2020.pdf, AMS_2018.pdf, AMS_2022.pdf"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "history = []\n",
    "response, history = chat(\"What types of lubricants are to be avoided when designing space mechanisms?\", history)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "When using Perf luoropolyethers (PFPE), failures have occurred due to degradation of the lubricant, resulting in increased friction coefficients, material wear, and component failure. This degradation is often referred to as the \"Brown Sugar\" effect, characterized by the residue resembling the color and texture of brown sugar. PFPE lubricants, although highly chemically inert, are subject to breakdown under high stress environments, especially in the presence of Lewis acids. This breakdown can lead to lubricant starvation, increased wear, and the generation of friction polymers and metallic fluorides, which may initially improve performance but ultimately contribute to further degradation.\n",
       "\n",
       "Source: AMS_2022.pdf, AMS_2018.pdf"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response, history = chat(\"Can you speak to what failures have occurred when using Perf luoropolyethers (PFPE)?\", history)\n",
    "display(Markdown(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
